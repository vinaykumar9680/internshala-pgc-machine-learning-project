{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea107a18-d3ef-41ae-91e4-8b1da099442e",
   "metadata": {},
   "source": [
    "# <B>  Additional Question </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7c83c0-35f1-4d46-a43d-ee954196e2ad",
   "metadata": {},
   "source": [
    " ## <b> Q1 Your views about the problem statement? </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b588f27d-5f9c-4e4a-bbe2-e47246c7ba0b",
   "metadata": {},
   "source": [
    "- **Company Background:** TechWorks Consulting is a company specializing in IT talent recruitment, and highlights its unique approach to matching skilled IT professionals with job opportunities.The company has very good image in market to place employees and sequre deserving pakages.\n",
    "- **Data Description:** The Dataset conatins information about colleges, cities, roles, previous experience, and salary. This information will be used to train and test the predictive model.We have to 2 additional dataset for colleges and city which help to divide colleges into tier 1 tier 2 tier 3 and city into metro or non metro city\n",
    "- **Regression Task:** The primary objective is to perform a regression task, where the aim is to predict a continuous variable, specifically the salary of newly hired employees.We can done it by all possible models and after than we have to choose the best.\n",
    "- **Role of Statistics:** Once the model is trained, statisticians would use statistical methods to evaluate its\r\n",
    "performance. One common method used in evaluating regression models is Mean Squared\r\n",
    "Error (MSE), which measures the average difference between the predicted salary and the\r\n",
    "actual salary. A lower MSE indicates that the model is making more accurate predictions. Other\r\n",
    "metrics like R-Squared and AIC can also be used to evaluate the model.\r\n",
    "Additionally, statisticians would also use statistical hypothesis testing to evaluate the\r\n",
    "significance of the model's coefficients and to make sure that the results are reliable and not just\r\n",
    "by chance.\n",
    "- **Data Preprocessing:** Data Preprocessing is most important task as it involves tasks like handling missing values, outliers, categorical variables, normalization, and feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e00507-fa0b-4c3f-b236-a62556e15059",
   "metadata": {},
   "source": [
    "## <b> Q2 What will be your approach to solving this task? </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c4d97-c35b-4b00-acd5-41fa9f6b3a81",
   "metadata": {},
   "source": [
    "##### Task : To create the Regression model for prediction of salary of new joining employees\n",
    "\n",
    "- **Data anlysing and loading:**\n",
    "  - In this step, we load the data and analyze it to understand what information is given in our dataset and how it can help us in building the model further.\n",
    "- **Data Preprocessing:**\n",
    "  - Handle Missing Values: Identify and address missing values by summary and then fill them and sure that there is no missing values in data.\n",
    "  - Outlier Detection and Treatment: Detect and handle outliers in the dataset, which could impact the model's accuracy.\n",
    "  - Dummy variable creation(categorical data): Transform categorical variables (e.g., \"College\" and \"City\") into 0 or 1.\n",
    "  - Normalize Data: Normalize numerical features to bring them to a common scale to avoid any feature dominating the model.\n",
    "  - Feature Selection: Use statistical techniques such as Lasso, Ridge, or correlation analysis to select the most relevant features for salary prediction.\n",
    "- **Train test split**\n",
    "   - diving the data into x and y then divide it into train data and test data for traning and testing of model.\n",
    "- **Model Selection and Statistics for accuracy :**\n",
    "    - Choose different regression models that are avialable for the given task like (Lasso regression,Ridge regression,Decision tree , Random forst ,         Boosting models ,Linear regression)\n",
    "\n",
    "     - Once the model is trained, statisticians would use statistical methods to evaluate its performance. One common method used in evaluating      regression models is Mean Squared Error (MSE), which measures the average difference between the predicted salary and the actual salary. A lower MSE indicates that the model is making more accurate predictions. Other metrics like R-Squared and AIC can also be used to evaluate the model. Additionally, statisticians would also use statistical hypothesis testing to evaluate the significance of the model's coefficients and to make sure that the results are reliable and not just by chance.\n",
    "- **Model Comparison:**\n",
    "    - Compare the performance of different models and select the one with the best accuracy and generalization.\n",
    "- **Further Improvement:**\n",
    "    - Consider additional techniques for model improvement, such as scaling, hyperparameter tuning, and ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0429587f-81ab-40e1-8118-62dd79247e3c",
   "metadata": {},
   "source": [
    "## <b> Q3 What were the available ML model options you had to perform this task? </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971b6129-93b1-437e-9295-94f831b7b793",
   "metadata": {},
   "source": [
    "#### -> It is a regression task so all the resgreesion models can be used here to predict the salary \n",
    "\n",
    "**1. Linear Regression:**\n",
    "- Linear regression is a simple and interpretable model that assumes a linear relationship between the features and the target variable (salary). It's a good starting point and can provide baseline performance.\n",
    "\n",
    "**2. Ridge Regression and Lasso Regression:**\n",
    "- Ridge and Lasso regression are regularization techniques that can be used to handle multicollinearity and prevent overfitting. They are variants of linear regression that add regularization terms to the cost function.\n",
    "\n",
    "**3. Simple Decision Trees:**\n",
    "- Decision tree is a tree based model that is udef to predict the classification as well as regression model it is very close to human thiking to approach th task\n",
    "\n",
    "**4. Random forest:** \n",
    " - A Random Forest model is an ensemble learning method used for classification and regression tasks. It operates by constructing multiple decision trees during training and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n",
    "\n",
    "**5. Bagging:** \n",
    "- Bagging, short for Bootstrap Aggregating, is an ensemble machine learning technique designed to improve the stability and accuracy of machine learning algorithms. It reduces variance and helps to prevent overfitting. The core idea behind bagging is to train multiple models on different subsets of the data and then combine their outputs to produce a more accurate and robust prediction. \n",
    "\n",
    "**6. Gradient boosting:**\n",
    " - Gradient Boosting is an ensemble learning technique used for both classification and regression tasks. It builds a model sequentially by adding new models (usually decision trees) that correct errors made by the previous models. Each new model is trained to predict the residuals or errors of the previous models, and their predictions are combined to produce a final output.\n",
    "\n",
    "**7. AdaBoost:** \n",
    " - AdaBoost, short for Adaptive Boosting, is an ensemble learning technique used for classification and regression tasks. It combines multiple weak learners, typically simple decision trees (called decision stumps), to create a strong predictive model. AdaBoost assigns weights to each training instance, increasing the weight of misclassified instances and decreasing the weight of correctly classified ones. In subsequent rounds, new models focus more on the harder-to-classify examples. The final prediction is a weighted majority vote of all the models.\n",
    "\n",
    "**8. XG boost:** \n",
    "- XGBoost, short for Extreme Gradient Boosting, is an advanced ensemble learning technique based on gradient boosting. It is designed to be highly efficient, flexible, and portable, often outperforming other algorithms due to its speed and accuracy. XGBoost uses a combination of decision trees and gradient boosting, optimizing model performance by minimizing errors more effectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf99715-3232-4f82-b99d-f88837d4d76f",
   "metadata": {},
   "source": [
    "## <b> Q4 Which model’s performance is best and what could be the possible reason for that? </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8befef6c-116f-4bec-8c0f-6de2eb487a3d",
   "metadata": {},
   "source": [
    "- If we consider R-squared as the primary metric for model performance, Random Forest is the top performer, followed by Linear Regression and Lasso. It's essential to consider other factors like computational efficiency, model interpretability, and the specific goals of your application when choosing the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5d9868-bb6d-44e5-b61d-abb750a103ca",
   "metadata": {},
   "source": [
    "## <b/> Q5 What steps can you take to improve this selected model’s performance even further? </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01008555-5ad4-4968-b33a-1fb92ac37463",
   "metadata": {},
   "source": [
    "#### Steps to increase model performance\n",
    "- **Increase the Number of Trees (Estimators):**\n",
    "    Random Forest's performance often benefits from increasing the number of decision trees (estimators) in the ensemble.\n",
    "- **Tune Hyperparameters:** Perform a more thorough hyperparameter tuning by experimenting with different values for parameters like max_depth, min_samples_split, min_samples_leaf, and max_features. Grid Search or Randomized Search can help find the optimal combination of hyperparameters.\n",
    "- **Feature Selection:** Consider removing or reducing the importance of less informative features to improve the model's efficiency and potentially its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b9750-aa1d-4056-bbf0-3e0a36c37b98",
   "metadata": {},
   "source": [
    "# <b> Project starting </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98386791-3308-462d-8f75-d7f55b017c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing basic needed libraries numpy , pandas and sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4149c05f-648c-499e-8503-fa1338ca0ec6",
   "metadata": {},
   "source": [
    "### <b> 1 Data loading <B/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d60af4df-b045-4391-8653-71cceb39a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a CSV file into a DataFrame to load the data\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/VINAY KUMAR PATEL/Downloads/machine learning/ml project/ML case Study.csv\",header=0)\n",
    "college = pd.read_csv(\"C:/Users/VINAY KUMAR PATEL/Downloads/machine learning/ml project/Colleges.csv\",header=0)\n",
    "cities = pd.read_csv(\"C:/Users/VINAY KUMAR PATEL/Downloads/machine learning/ml project/cities.csv\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce3d2146-5fe2-4641-8d08-bb58958fb8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>College</th>\n",
       "      <th>City</th>\n",
       "      <th>Role</th>\n",
       "      <th>Previous CTC</th>\n",
       "      <th>Previous job change</th>\n",
       "      <th>Graduation Marks</th>\n",
       "      <th>EXP (Month)</th>\n",
       "      <th>CTC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVNIT Surat</td>\n",
       "      <td>Asansol</td>\n",
       "      <td>Manager</td>\n",
       "      <td>55523.0</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>19</td>\n",
       "      <td>71406.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NIT Bhopal</td>\n",
       "      <td>Ajmer</td>\n",
       "      <td>Executive</td>\n",
       "      <td>57081.0</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>18</td>\n",
       "      <td>68005.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IEM, Kolkata</td>\n",
       "      <td>Rajpur Sonarpur</td>\n",
       "      <td>Executive</td>\n",
       "      <td>60347.0</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>76764.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KIIT, Bhubaneswar</td>\n",
       "      <td>Ajmer</td>\n",
       "      <td>Executive</td>\n",
       "      <td>49010.0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>33</td>\n",
       "      <td>82092.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTU</td>\n",
       "      <td>Durgapur</td>\n",
       "      <td>Executive</td>\n",
       "      <td>57879.0</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>32</td>\n",
       "      <td>73878.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             College             City       Role  Previous CTC  \\\n",
       "0        SVNIT Surat          Asansol    Manager       55523.0   \n",
       "1         NIT Bhopal            Ajmer  Executive       57081.0   \n",
       "2       IEM, Kolkata  Rajpur Sonarpur  Executive       60347.0   \n",
       "3  KIIT, Bhubaneswar            Ajmer  Executive       49010.0   \n",
       "4                DTU         Durgapur  Executive       57879.0   \n",
       "\n",
       "   Previous job change  Graduation Marks  EXP (Month)       CTC  \n",
       "0                    3                66           19  71406.58  \n",
       "1                    1                84           18  68005.87  \n",
       "2                    2                52           28  76764.02  \n",
       "3                    2                81           33  82092.39  \n",
       "4                    4                74           32  73878.10  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the data that we leaded\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d842194-f2bf-4030-9032-fd09d650c082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tier 1</th>\n",
       "      <th>Tier 2</th>\n",
       "      <th>Tier 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IIT Bombay</td>\n",
       "      <td>IIIT Bangalore</td>\n",
       "      <td>Ramaiah Institute of Technology, Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IIT Delhi</td>\n",
       "      <td>IIIT Delhi</td>\n",
       "      <td>TIET/Thapar University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IIT Kharagpur</td>\n",
       "      <td>IGDTUW</td>\n",
       "      <td>Manipal Main Campus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IIT Madras</td>\n",
       "      <td>NIT Calicut</td>\n",
       "      <td>VIT Vellore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IIT Kanpur</td>\n",
       "      <td>IIITM Gwalior</td>\n",
       "      <td>SRM Main Campus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tier 1          Tier 2                                      Tier 3\n",
       "0     IIT Bombay  IIIT Bangalore  Ramaiah Institute of Technology, Bengaluru\n",
       "1      IIT Delhi      IIIT Delhi                      TIET/Thapar University\n",
       "2  IIT Kharagpur          IGDTUW                         Manipal Main Campus\n",
       "3     IIT Madras     NIT Calicut                                 VIT Vellore\n",
       "4     IIT Kanpur   IIITM Gwalior                             SRM Main Campus"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the data that we leaded\n",
    "college.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11537d2c-aa53-4922-9cc8-ba2f59564f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrio City</th>\n",
       "      <th>non-metro cities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Dehradun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Durgapur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Asansol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chennai</td>\n",
       "      <td>Rourkela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Kozhikode</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metrio City non-metro cities\n",
       "0      Mumbai         Dehradun\n",
       "1       Delhi         Durgapur\n",
       "2     Kolkata          Asansol\n",
       "3     Chennai         Rourkela\n",
       "4   Bangalore        Kozhikode"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the data that we leaded\n",
    "cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f227e03-e27d-44c2-b480-28583ba77e18",
   "metadata": {},
   "source": [
    "### <b> 2. Data Preprocessing <B/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb906ecc-d37c-42e3-ab0a-649cfb8536ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''    Extract data from the \"Tier 1,\" \"Tier 2,\" and \"Tier 3\" columns of the 'college' DataFrame and then load it to ml case study csv to get\n",
    "colleges 'tier 1' 'tier 2' and 'tier 3'.     '''\n",
    "\n",
    "Tier1 = college[\"Tier 1\"].tolist()\n",
    "Tier2 = college[\"Tier 2\"].tolist()\n",
    "Tier3 = college[\"Tier 3\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "632fdd01-b5f9-4d73-9e05-9d2b2f574211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IIIT Bangalore',\n",
       " 'IIIT Delhi',\n",
       " 'IGDTUW',\n",
       " 'NIT Calicut',\n",
       " 'IIITM Gwalior',\n",
       " 'IIIT Lucknow',\n",
       " 'MNNIT Allahabad',\n",
       " 'Punjab Engineering College',\n",
       " 'DAIICT',\n",
       " 'MNIT Jaipur',\n",
       " 'NIT Durgapur',\n",
       " 'VNIT Nagpur',\n",
       " 'LNMIIT',\n",
       " 'BIT Mesra',\n",
       " 'SVNIT Surat',\n",
       " 'NIT Jalandhar',\n",
       " 'NIT Jamshedpur',\n",
       " 'NIT Kurukshetra',\n",
       " 'NIT Patna',\n",
       " 'NIT Raipur',\n",
       " 'NIT Bhopal',\n",
       " 'NIT Rourkela',\n",
       " 'NIT Silchar',\n",
       " 'NIT Sikkim',\n",
       " 'IIIT Jabalpur',\n",
       " 'Jalpaiguri Government Engineering College',\n",
       " 'IIEST/BESU Shibpur',\n",
       " 'R.V. College of Engineering']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing data contains in Tier2\n",
    "\n",
    "Tier2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abc3a895-6298-4ea2-8824-9bb9f521e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using for loop and if else to assign the values Tier 1 , Tier 2 , Tier 3 to the ML case study csv file\n",
    "# If college comes in tier 1 list then assign the 1 .\n",
    "# If college comes in tier 2 list then assign the 2 .\n",
    "# If college comes in tier 1 list then assign the 1 .\n",
    "\n",
    "for item in df.College:\n",
    "    if item in Tier1:\n",
    "        df[\"College\"].replace(item,3,inplace=True)\n",
    "    elif item in Tier2:\n",
    "        df[\"College\"].replace(item,2,inplace=True)\n",
    "    elif item in Tier3:\n",
    "        df[\"College\"].replace(item,1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef35e4bb-c8f0-4e93-91c2-243d4c27f3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>College</th>\n",
       "      <th>City</th>\n",
       "      <th>Role</th>\n",
       "      <th>Previous CTC</th>\n",
       "      <th>Previous job change</th>\n",
       "      <th>Graduation Marks</th>\n",
       "      <th>EXP (Month)</th>\n",
       "      <th>CTC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Asansol</td>\n",
       "      <td>Manager</td>\n",
       "      <td>55523.0</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>19</td>\n",
       "      <td>71406.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ajmer</td>\n",
       "      <td>Executive</td>\n",
       "      <td>57081.0</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>18</td>\n",
       "      <td>68005.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Rajpur Sonarpur</td>\n",
       "      <td>Executive</td>\n",
       "      <td>60347.0</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>76764.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Ajmer</td>\n",
       "      <td>Executive</td>\n",
       "      <td>49010.0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>33</td>\n",
       "      <td>82092.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Durgapur</td>\n",
       "      <td>Executive</td>\n",
       "      <td>57879.0</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>32</td>\n",
       "      <td>73878.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   College             City       Role  Previous CTC  Previous job change  \\\n",
       "0        2          Asansol    Manager       55523.0                    3   \n",
       "1        2            Ajmer  Executive       57081.0                    1   \n",
       "2        1  Rajpur Sonarpur  Executive       60347.0                    2   \n",
       "3        1            Ajmer  Executive       49010.0                    2   \n",
       "4        3         Durgapur  Executive       57879.0                    4   \n",
       "\n",
       "   Graduation Marks  EXP (Month)       CTC  \n",
       "0                66           19  71406.58  \n",
       "1                84           18  68005.87  \n",
       "2                52           28  76764.02  \n",
       "3                81           33  82092.39  \n",
       "4                74           32  73878.10  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1d6062b-e5d9-4969-994b-7255bf83fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting lists of metropolitan and non-metropolitan cities from the 'cities' DataFrame\n",
    "\n",
    "metro = cities['Metrio City'].tolist()\n",
    "non_metro_cities = cities['non-metro cities'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3d301a0-bfcc-44d4-980d-d7adc5168154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating previpus steps and assigning value as 1 if city is merto and 0 if non metro\n",
    "\n",
    "for item in df.City:\n",
    "    if item in metro:\n",
    "        df['City'].replace(item,1,inplace=True)\n",
    "    elif item in non_metro_cities:\n",
    "        df['City'].replace(item,0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26a1cec8-1666-4d07-b6e1-677f7622df81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>College</th>\n",
       "      <th>City</th>\n",
       "      <th>Role</th>\n",
       "      <th>Previous CTC</th>\n",
       "      <th>Previous job change</th>\n",
       "      <th>Graduation Marks</th>\n",
       "      <th>EXP (Month)</th>\n",
       "      <th>CTC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>55523.0</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>19</td>\n",
       "      <td>71406.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>57081.0</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>18</td>\n",
       "      <td>68005.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>60347.0</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>76764.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>49010.0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>33</td>\n",
       "      <td>82092.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>57879.0</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>32</td>\n",
       "      <td>73878.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   College  City       Role  Previous CTC  Previous job change  \\\n",
       "0        2     0    Manager       55523.0                    3   \n",
       "1        2     0  Executive       57081.0                    1   \n",
       "2        1     0  Executive       60347.0                    2   \n",
       "3        1     0  Executive       49010.0                    2   \n",
       "4        3     0  Executive       57879.0                    4   \n",
       "\n",
       "   Graduation Marks  EXP (Month)       CTC  \n",
       "0                66           19  71406.58  \n",
       "1                84           18  68005.87  \n",
       "2                52           28  76764.02  \n",
       "3                81           33  82092.39  \n",
       "4                74           32  73878.10  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93829491-9651-4ccb-9d9b-759f15b85315",
   "metadata": {},
   "source": [
    "- <B> Dummy variable creation </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3828fc7e-4031-43e0-9571-50a6d5910357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummy for cateogarical column\n",
    "\n",
    "df = pd.get_dummies(df, drop_first=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f85094b-07fb-44be-b1f4-032ab1839e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>College</th>\n",
       "      <th>City</th>\n",
       "      <th>Previous CTC</th>\n",
       "      <th>Previous job change</th>\n",
       "      <th>Graduation Marks</th>\n",
       "      <th>EXP (Month)</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Role_Manager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>55523</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>19</td>\n",
       "      <td>71406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>57081</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>18</td>\n",
       "      <td>68005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60347</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>76764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49010</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>33</td>\n",
       "      <td>82092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>57879</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>32</td>\n",
       "      <td>73878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   College  City  Previous CTC  Previous job change  Graduation Marks  \\\n",
       "0        2     0         55523                    3                66   \n",
       "1        2     0         57081                    1                84   \n",
       "2        1     0         60347                    2                52   \n",
       "3        1     0         49010                    2                81   \n",
       "4        3     0         57879                    4                74   \n",
       "\n",
       "   EXP (Month)    CTC  Role_Manager  \n",
       "0           19  71406             1  \n",
       "1           18  68005             0  \n",
       "2           28  76764             0  \n",
       "3           33  82092             0  \n",
       "4           32  73878             0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de36bf0b-909c-4d6c-9b53-73da6c72306c",
   "metadata": {},
   "source": [
    " - <b> Checking for null value </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c639c8e5-542e-4a88-998c-ba2d98c14cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>College</th>\n",
       "      <th>City</th>\n",
       "      <th>Previous CTC</th>\n",
       "      <th>Previous job change</th>\n",
       "      <th>Graduation Marks</th>\n",
       "      <th>EXP (Month)</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Role_Manager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1589.000000</td>\n",
       "      <td>1589.000000</td>\n",
       "      <td>1589.000000</td>\n",
       "      <td>1589.000000</td>\n",
       "      <td>1589.000000</td>\n",
       "      <td>1589.000000</td>\n",
       "      <td>1589.000000</td>\n",
       "      <td>1589.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.024544</td>\n",
       "      <td>0.514160</td>\n",
       "      <td>55518.453744</td>\n",
       "      <td>2.528634</td>\n",
       "      <td>59.855255</td>\n",
       "      <td>39.044682</td>\n",
       "      <td>75352.790434</td>\n",
       "      <td>0.206419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.838330</td>\n",
       "      <td>0.499957</td>\n",
       "      <td>6655.218445</td>\n",
       "      <td>1.123918</td>\n",
       "      <td>14.935139</td>\n",
       "      <td>14.108875</td>\n",
       "      <td>12587.293679</td>\n",
       "      <td>0.404862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36990.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>53020.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50518.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>66902.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55291.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>73028.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60109.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>80588.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>77911.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>123416.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           College         City  Previous CTC  Previous job change  \\\n",
       "count  1589.000000  1589.000000   1589.000000          1589.000000   \n",
       "mean      2.024544     0.514160  55518.453744             2.528634   \n",
       "std       0.838330     0.499957   6655.218445             1.123918   \n",
       "min       1.000000     0.000000  36990.000000             1.000000   \n",
       "25%       1.000000     0.000000  50518.000000             2.000000   \n",
       "50%       2.000000     1.000000  55291.000000             3.000000   \n",
       "75%       3.000000     1.000000  60109.000000             4.000000   \n",
       "max       3.000000     1.000000  77911.000000             4.000000   \n",
       "\n",
       "       Graduation Marks  EXP (Month)            CTC  Role_Manager  \n",
       "count       1589.000000  1589.000000    1589.000000   1589.000000  \n",
       "mean          59.855255    39.044682   75352.790434      0.206419  \n",
       "std           14.935139    14.108875   12587.293679      0.404862  \n",
       "min           35.000000    18.000000   53020.000000      0.000000  \n",
       "25%           46.000000    26.000000   66902.000000      0.000000  \n",
       "50%           60.000000    39.000000   73028.000000      0.000000  \n",
       "75%           73.000000    51.000000   80588.000000      0.000000  \n",
       "max           85.000000    64.000000  123416.000000      1.000000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f249a-1a2f-40e9-9eaa-754b878be996",
   "metadata": {},
   "source": [
    "#####  Note:- There is no null values in the data as we see the describe command count values are same in all. so, no need to fill null values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca0834a-b8be-4433-85b6-930ea4426b17",
   "metadata": {},
   "source": [
    "- <B> Correlation Analysis </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d04cd4c-4eae-484b-9a88-2b1372de16a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>College</th>\n",
       "      <th>City</th>\n",
       "      <th>Previous CTC</th>\n",
       "      <th>Previous job change</th>\n",
       "      <th>Graduation Marks</th>\n",
       "      <th>EXP (Month)</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Role_Manager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>College</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014946</td>\n",
       "      <td>-0.041979</td>\n",
       "      <td>0.055060</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>-0.011752</td>\n",
       "      <td>0.029592</td>\n",
       "      <td>0.014749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <td>0.014946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>0.051670</td>\n",
       "      <td>-0.018616</td>\n",
       "      <td>-0.023613</td>\n",
       "      <td>-0.020365</td>\n",
       "      <td>-0.048671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Previous CTC</th>\n",
       "      <td>-0.041979</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>-0.032976</td>\n",
       "      <td>0.119163</td>\n",
       "      <td>0.257998</td>\n",
       "      <td>0.012321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Previous job change</th>\n",
       "      <td>0.055060</td>\n",
       "      <td>0.051670</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019267</td>\n",
       "      <td>0.023488</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>-0.017150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graduation Marks</th>\n",
       "      <td>-0.003539</td>\n",
       "      <td>-0.018616</td>\n",
       "      <td>-0.032976</td>\n",
       "      <td>0.019267</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.057061</td>\n",
       "      <td>-0.005449</td>\n",
       "      <td>0.017858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXP (Month)</th>\n",
       "      <td>-0.011752</td>\n",
       "      <td>-0.023613</td>\n",
       "      <td>0.119163</td>\n",
       "      <td>0.023488</td>\n",
       "      <td>-0.057061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.301117</td>\n",
       "      <td>-0.026751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTC</th>\n",
       "      <td>0.029592</td>\n",
       "      <td>-0.020365</td>\n",
       "      <td>0.257998</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>-0.005449</td>\n",
       "      <td>0.301117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.621310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Role_Manager</th>\n",
       "      <td>0.014749</td>\n",
       "      <td>-0.048671</td>\n",
       "      <td>0.012321</td>\n",
       "      <td>-0.017150</td>\n",
       "      <td>0.017858</td>\n",
       "      <td>-0.026751</td>\n",
       "      <td>0.621310</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      College      City  Previous CTC  Previous job change  \\\n",
       "College              1.000000  0.014946     -0.041979             0.055060   \n",
       "City                 0.014946  1.000000      0.004644             0.051670   \n",
       "Previous CTC        -0.041979  0.004644      1.000000             0.005756   \n",
       "Previous job change  0.055060  0.051670      0.005756             1.000000   \n",
       "Graduation Marks    -0.003539 -0.018616     -0.032976             0.019267   \n",
       "EXP (Month)         -0.011752 -0.023613      0.119163             0.023488   \n",
       "CTC                  0.029592 -0.020365      0.257998             0.011370   \n",
       "Role_Manager         0.014749 -0.048671      0.012321            -0.017150   \n",
       "\n",
       "                     Graduation Marks  EXP (Month)       CTC  Role_Manager  \n",
       "College                     -0.003539    -0.011752  0.029592      0.014749  \n",
       "City                        -0.018616    -0.023613 -0.020365     -0.048671  \n",
       "Previous CTC                -0.032976     0.119163  0.257998      0.012321  \n",
       "Previous job change          0.019267     0.023488  0.011370     -0.017150  \n",
       "Graduation Marks             1.000000    -0.057061 -0.005449      0.017858  \n",
       "EXP (Month)                 -0.057061     1.000000  0.301117     -0.026751  \n",
       "CTC                         -0.005449     0.301117  1.000000      0.621310  \n",
       "Role_Manager                 0.017858    -0.026751  0.621310      1.000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2092e31-a16a-4825-86b3-09b0d0ed30b2",
   "metadata": {},
   "source": [
    "#####  Note:- By seeing the correlation matrix we can say that there is no columns which are highly correlated because in diffrent colums there is no diffrent columns pair having value greater than 0.80 and less than -0.80 . so, no need to remove any column "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bcdedb-06e5-45bf-8955-727129e9d7cd",
   "metadata": {},
   "source": [
    "- <B> Outliers treatment </B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3803501-7fc1-49ae-ba98-e894c292859c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Previous CTC'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGKCAYAAAAR/3XJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAos0lEQVR4nO3de3TU5Z3H8c/kNgSaDOGSDEFA1ATltutiGy7tBuUmB4RdWygbCLYirIYKQQKV1V3Aw20RYY+CQFpXFqVEe5AqFXPA9Rw4SLgYlnUDJdAjck24lMkMakhC8uwfLr/tkIDP2MQZwvt1zhwyv+c7+X1/AZ1PnnnmGZcxxggAAAA3FRXuBgAAAG4FhCYAAAALhCYAAAALhCYAAAALhCYAAAALhCYAAAALhCYAAAALhCYAAAALMeFuoDmpq6vT2bNnlZCQIJfLFe52AACABWOMLl++rNTUVEVF3Xg+idDUiM6ePatOnTqFuw0AAPAtnDp1SnfccccNxwlNjSghIUHS1z/0xMTEMHcDAABsBAIBderUyXkevxFCUyO69pJcYmIioQkAgFvMNy2tYSE4AACABUITAACABUITAACABUITAACABUITAACABUITAACABUITAACABUITAACABTa3BIBvUF1drXfffVdnz55VamqqRo8erbi4uHC3BeA7RmgCgJtYs2aNfvvb36q2tjbo2JgxY/Tkk0+GsTMA3zVCEwDcwJo1a1RQUKCkpCRNmjRJ/fr1U1FRkV577TUVFBRIEsEJuI24jDEm3E00F4FAQB6PR36/n8+eA25x1dXVGj58uBITE/Xb3/5WMTH//zvm1atXNWbMGAUCAX3wwQe8VAfc4myfv1kIDgANePfdd1VbW6tJkyYFBSZJiomJ0eOPP67a2lq9++67YeoQwHeN0AQADTh79qwkqV+/fg2OXzt+rQ5A80doAoAGpKamSpKKiooaHL92/FodgOaP0AQADRg9erSio6P12muv6erVq0FjV69e1b//+78rOjpao0ePDlOHAL5rhCYAaEBcXJzGjBkjn8+nMWPGaMuWLbp48aK2bNkSdJxF4MDtgy0HAOAGrm0n8Pbbb+ull15yjkdHR2vcuHFsNwDcZphpAoCb6N69u9q3bx90rF27durevXuYOgIQLoQmALiBnTt3au7cubr77ru1atUqbd26VatWrdLdd9+tuXPnaufOneFuEcB3iM0tGxGbWwLNR21trcaPH6+77rpLCxYsUFTU//+OWVdXp+eff17Hjx/Xm2++qejo6DB2CuAvxeaWAPAX+PTTT1VeXq7x48cHBSZJioqK0vjx41VWVqZPP/00TB0C+K4RmgCgAZcuXZIkde3atcHxa8ev1QFo/nj3HAA0oE2bNpKk48eP695779Wnn36qS5cuqU2bNurdu7eOHz8eVAeg+SM0AUADevfuLa/Xq5dffll+v1/l5eXOmNfrlcfjUYcOHdS7d+8wdgngu8TLcwDQgOjoaA0cOFClpaWqqqpSXl6eNm3apLy8PFVVVam0tFSZmZksAgduI7x7rhHx7jmg+bj27jmPx6OKigqdO3fOGbs20xQIBHj3HNAM8O45APgLXHv33N/+7d/WGzPG6Ec/+hHvngNuM6xpAoAGXHtX3K9+9Sv1799f//Iv/6KuXbvq+PHj2rBhg379618H1QFo/phpAoAGtG7dWpLUq1cvLViwQD169FDLli3Vo0cPLViwQL169QqqA9D8EZoAAAAsEJoAoAEVFRWSpJKSEj3//PM6dOiQvvrqKx06dEjPP/+8SkpKguoANH+saQKABlzbtPKJJ57Qli1bNHXqVGesQ4cOeuKJJ/SrX/2KzS2B2wihCQAacG1zy0OHDumNN95QSUmJsyN4z549NXfuXDa3BG4zvDwHAA2Ijo5WTk6OioqKNHfuXMXFxalfv36Ki4vT3LlzVVRUpKeeeoo9moDbCJtbNiI2twSan507d+rVV18N+hiVDh066KmnnmpwDycAtx7b529CUyMiNAHNU21tbb0P7GWGCWg+bJ+/WdMEAN8gOjpa999/f7jbABBmrGkCAACwQGgCAACwQGgCAACwQGgCAACwwEJwIEJduXJFJ0+eDHcbQMTq3LmzWrRoEe42cBshNAER6uTJk5oyZUq42wAiVn5+vtLT08PdBm4jhCYgQnXu3Fn5+fnhbgP/58SJE1q4cKGee+45denSJdztQF//NwJ8lwhNQIRq0aIFv0VHoC5duvD3AtymWAgOAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABggdAEAABgIayh6c4775TL5ap3mzp1qiTJGKN58+YpNTVV8fHxGjhwoA4dOhT0PaqqqvT000+rXbt2atWqlUaNGqXTp08H1fh8PmVnZ8vj8cjj8Sg7O1sVFRVBNSdPntQjjzyiVq1aqV27dpo2bZqqq6ub9PoBAMCtI6yhaf/+/SorK3Nu27dvlySNGTNGkrR06VItX75cK1eu1P79++X1ejVkyBBdvnzZ+R65ubnavHmzCgoKtGvXLn3xxRcaOXKkamtrnZqsrCwdPHhQhYWFKiws1MGDB5Wdne2M19bWasSIEfryyy+1a9cuFRQUaNOmTZo5c+Z39JMAAAARz0SQ6dOnm7vvvtvU1dWZuro64/V6zZIlS5zxK1euGI/HY9asWWOMMaaiosLExsaagoICp+bMmTMmKirKFBYWGmOMOXz4sJFk9uzZ49QUFRUZSebIkSPGGGO2bt1qoqKizJkzZ5yajRs3Grfbbfx+v3X/fr/fSArpMQBuDaWlpSYzM9OUlpaGuxUAjcz2+Tti1jRVV1frzTff1OOPPy6Xy6Xjx4+rvLxcQ4cOdWrcbrcyMzO1e/duSVJxcbFqamqCalJTU9WzZ0+npqioSB6PRxkZGU5N37595fF4gmp69uyp1NRUp2bYsGGqqqpScXHxDXuuqqpSIBAIugEAgOYpYkLT7373O1VUVOhnP/uZJKm8vFySlJKSElSXkpLijJWXlysuLk5JSUk3rUlOTq53vuTk5KCa68+TlJSkuLg4p6YhixcvdtZJeTwederUKYQrBgAAt5KICU2vvfaahg8fHjTbI0kulyvovjGm3rHrXV/TUP23qbnenDlz5Pf7ndupU6du2hcAALh1RURoOnHihD788EM98cQTzjGv1ytJ9WZ6zp8/78wKeb1eVVdXy+fz3bTm3Llz9c554cKFoJrrz+Pz+VRTU1NvBurPud1uJSYmBt0AAEDzFBGh6fXXX1dycrJGjBjhHOvatau8Xq/zjjrp63VPO3bsUP/+/SVJffr0UWxsbFBNWVmZSkpKnJp+/frJ7/dr3759Ts3evXvl9/uDakpKSlRWVubUbNu2TW63W3369GmaiwYAALeUmHA3UFdXp9dff12PPfaYYmL+vx2Xy6Xc3FwtWrRIaWlpSktL06JFi9SyZUtlZWVJkjwejyZNmqSZM2eqbdu2atOmjfLy8tSrVy8NHjxYknTffffp4Ycf1uTJk7V27VpJ0pQpUzRy5Eh169ZNkjR06FB1795d2dnZevHFF3Xp0iXl5eVp8uTJzB4BAABJERCaPvzwQ508eVKPP/54vbHZs2ersrJSOTk58vl8ysjI0LZt25SQkODUrFixQjExMRo7dqwqKys1aNAgrVu3TtHR0U7Nhg0bNG3aNOdddqNGjdLKlSud8ejoaL3//vvKycnRgAEDFB8fr6ysLC1btqwJrxwAANxKXMYYE+4mmotAICCPxyO/388MFdDMHD16VFOmTFF+fr7S09PD3Q6ARmT7/B0Ra5oAAAAiHaEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAAqEJAADAgnVoOnv2rPLy8hQIBOqN+f1+zZo1S+fOnWvU5gAAACKFdWhavny5AoGAEhMT6415PB5dvnxZy5cvb9TmAAAAIoV1aCosLNTEiRNvOD5x4kT9/ve/b5SmAAAAIo11aDp+/Lg6d+58w/E77rhDn3/+eWP0BAAAEHGsQ1N8fPxNQ9Hnn3+u+Pj4xugJAAAg4liHpoyMDL3xxhs3HF+/fr1+8IMfNEpTAAAAkSbGtjAvL09DhgyRx+PRrFmzlJKSIkk6d+6cli5dqnXr1mnbtm1N1igAAEA4WYemBx98UKtWrdL06dO1YsUKJSYmyuVyye/3KzY2Vq+88ooeeuihpuwVAAAgbKxD0wsvvKC8vDyNHDlSb7/9tv74xz/KGKP09HT95Cc/0R133NGUfQIAAISVdWiaP3++nnzySXXs2FEzZsxoyp4AAAAijvVCcGNMU/YBAAAQ0UL67DmXy9VUfQAAAEQ065fnJGnQoEGKibn5Qw4cOPAXNQQAABCJQgpNw4YN0/e+972m6gUAACBihRSaZs2apeTk5KbqBQAAIGJZr2liPRMAALid8e45AAAAC9ah6bPPPlNsbKzq6urqjdXW1ioQCDRqYwAAAJHEOjT913/9lzIyMnTlypV6Y1VVVfr+97+vLVu2hNzAmTNnNGHCBLVt21YtW7bUX//1X6u4uNgZN8Zo3rx5Sk1NVXx8vAYOHKhDhw7VO//TTz+tdu3aqVWrVho1apROnz4dVOPz+ZSdnS2PxyOPx6Ps7GxVVFQE1Zw8eVKPPPKIWrVqpXbt2mnatGmqrq4O+ZoAAEDzYx2aVq9erdmzZ6tly5b1xlq2bKlf/vKXWrlyZUgn9/l8GjBggGJjY/XBBx/o8OHDeumll9S6dWunZunSpVq+fLlWrlyp/fv3y+v1asiQIbp8+bJTk5ubq82bN6ugoEC7du3SF198oZEjR6q2ttapycrK0sGDB1VYWKjCwkIdPHhQ2dnZznhtba1GjBihL7/8Urt27VJBQYE2bdqkmTNnhnRNAACgmTKWOnToYI4dO3bD8WPHjpkOHTrYfjtjjDG//OUvzQ9/+MMbjtfV1Rmv12uWLFniHLty5YrxeDxmzZo1xhhjKioqTGxsrCkoKHBqzpw5Y6KiokxhYaExxpjDhw8bSWbPnj1OTVFRkZFkjhw5YowxZuvWrSYqKsqcOXPGqdm4caNxu93G7/dbXY/f7zeSrOsB3DpKS0tNZmamKS0tDXcrABqZ7fO39ZYDPp9PV69eveF4TU2NfD5fSIHtvffe07BhwzRmzBjt2LFDHTt2VE5OjiZPnixJOn78uMrLyzV06FDnMW63W5mZmdq9e7f+8R//UcXFxaqpqQmqSU1NVc+ePbV7924NGzZMRUVF8ng8ysjIcGr69u0rj8ej3bt3q1u3bioqKlLPnj2Vmprq1AwbNkxVVVUqLi7Wgw8+WK//qqoqVVVVOfeby7quc+fOye/3h7sNIKKcOHEi6E8AX/N4PEpJSQl3G98J69B055136pNPPtG9997b4Pgnn3yiLl26hHTyzz77TKtXr9Yzzzyjf/qnf9K+ffs0bdo0ud1uTZw4UeXl5ZJU7y8jJSXF+R9XeXm54uLilJSUVK/m2uPLy8sb3F8qOTk5qOb68yQlJSkuLs6pud7ixYs1f/78kK450p07d04Tsieqprrqm4uB29DChQvD3QIQUWLj3HrzjfW3RXCyDk2PPvqonnvuOQ0ZMqTeD6a8vFzPP/+8JkyYENLJ6+rq9MADD2jRokWSpPvvv1+HDh3S6tWrNXHiRKfu+j2ijDHfuG/U9TUN1X+bmj83Z84cPfPMM879QCCgTp063bSvSOf3+1VTXaXKuzJV18IT7nYAABEs6opf+myH/H4/oenPPfvss3r33XeVlpamCRMmqFu3bnK5XPrDH/6gDRs2qFOnTnr22WdDOnmHDh3UvXv3oGP33XefNm3aJEnyer2Svg5lHTp0cGrOnz/v/OV4vV5VV1fL5/MFzTadP39e/fv3d2rOnTtX7/wXLlwI+j579+4NGvf5fKqpqbnhPwS32y232x3SNd8q6lp4VNeqXbjbAAAgYli/ey4hIUEff/yxJkyYoLfeekszZsxQbm6u3n77bU2YMEEff/yxEhISQjr5gAEDVFpaGnTs6NGjzst8Xbt2ldfr1fbt253x6upq7dixwwlEffr0UWxsbFBNWVmZSkpKnJp+/frJ7/dr3759Ts3evXvl9/uDakpKSlRWVubUbNu2TW63W3369AnpugAAQPMT0mfPeTwevfrqq1q1apUuXrwoY4zat2//rT9iZcaMGerfv78WLVqksWPHat++fcrPz1d+fr6kr18uy83N1aJFi5SWlqa0tDQtWrRILVu2VFZWltPTpEmTNHPmTLVt21Zt2rRRXl6eevXqpcGDB0v6evbq4Ycf1uTJk7V27VpJ0pQpUzRy5Eh169ZNkjR06FB1795d2dnZevHFF3Xp0iXl5eVp8uTJSkxM/FbXBwAAmo+QQtM1LpdL7du3/4tP/v3vf1+bN2/WnDlz9MILL6hr1676t3/7N40fP96pmT17tiorK5WTkyOfz6eMjAxt27YtaFZrxYoViomJ0dixY1VZWalBgwZp3bp1io6Odmo2bNigadOmOe+yGzVqVNC+UtHR0Xr//feVk5OjAQMGKD4+XllZWVq2bNlffJ0AAODW5zKGD5VrLIFAQB6PR36//5adnTp69KimTJmiL7uPYk0TAOCmor68qFaH31N+fr7S09PD3c63Zvv8bb2mCQAA4HZGaAIAALDQKKHp+g++BQAAaG5CDk3/+q//qrfeesu5P3bsWLVt21YdO3bUf//3fzdqcwAAAJEi5NC0du1aZ9fr7du3a/v27frggw80fPhwzZo1q9EbBAAAiAQhbzlQVlbmhKbf//73Gjt2rIYOHao777wz6ANxAQAAmpOQZ5qSkpJ06tQpSVJhYaGzgaQxRrW1tY3bHQAAQIQIeabp0UcfVVZWltLS0vSnP/1Jw4cPlyQdPHhQ99xzT6M3CAAAEAlCDk0rVqzQnXfeqVOnTmnp0qX63ve+J+nrl+1ycnIavUEAAIBIEHJoio2NVV5eXr3jubm5jdEPAABARAo5NK1fv/6m4xMnTvzWzQAAAESqkEPT9OnTg+7X1NToq6++UlxcnFq2bEloAgAAzVLI757z+XxBty+++EKlpaX64Q9/qI0bNzZFjwAAAGHXKB+jkpaWpiVLltSbhQIAAGguGu0De6Ojo3X27NnG+nYAAAARJeQ1Te+9917QfWOMysrKtHLlSg0YMKDRGgMAAIgkIYemv/u7vwu673K51L59ez300EN66aWXGqsvAACAiBJyaKqrq2uKPgAAACLaX7SmyRgjY0xj9QIAABCxvlVoWr9+vXr16qX4+HjFx8erd+/eeuONNxq7NwAAgIgR8stzy5cv1z//8z/rF7/4hQYMGCBjjD7++GM9+eSTunjxombMmNEUfQIAAIRVyKHplVde0erVq4N2/h49erR69OihefPmEZoAAECzFPLLc2VlZerfv3+94/3791dZWVmjNAUAABBpQg5N99xzj95+++16x9966y2lpaU1SlMAAACRJuSX5+bPn6+f/vSn2rlzpwYMGCCXy6Vdu3bpP//zPxsMUwAAAM1ByDNNP/7xj7V37161a9dOv/vd7/TOO++oXbt22rdvn/7+7/++KXoEAAAIu5BnmiSpT58+evPNNxu7FwAAgIhlFZoCgYASExOdr2/mWh0AAEBzYhWakpKSVFZWpuTkZLVu3Voul6tejTFGLpdLtbW1jd4kAABAuFmFpo8++kht2rRxvm4oNAEAADRnVqEpMzPT+XrgwIFN1QsAAEDECnkh+F133aXx48drwoQJ6tatW1P0hAgQVVkR7hYAABHudnuuCDk0/eIXv9DGjRu1cOFC3X///crOztZPf/pTdejQoSn6Q5jEH98Z7hYAAIgoIYemZ555Rs8884yOHj2qDRs2aPXq1Zo1a5YefPBBTZgwIegz6XDrquz6t6qLbx3uNgAAESyqsuK2+iX7W+3TJEnp6emaP3++5s+frz179uipp57Sz3/+c0JTM1EX31p1rdqFuw0AACLGtw5NkrRv3z795je/0VtvvSW/36+f/OQnjdUXAABARAk5NF17We43v/mNPv/8cz344INasmSJHn30USUkJDRFjwAAAGEXcmi699579cADD2jq1KkaN26cvF5vU/QFAAAQUUIOTUeOHFF6enpT9AIAABCxokJ9QHp6uioqKvTrX/9ac+bM0aVLlyRJBw4c0JkzZxq9QQAAgEgQ8kzTp59+qkGDBql169b6/PPPNXnyZLVp00abN2/WiRMntH79+qboEwAAIKxCnmmaMWOGfv7zn+vYsWNq0aKFc3z48OHaufP22asBAADcXkKeafrkk0+Un59f73jHjh1VXl7eKE0BAABEmpBnmlq0aKFAIFDveGlpqdq3b98oTQEAAESakEPT6NGj9cILL6impkaS5HK5dPLkST377LP68Y9/3OgNAgAARIKQQ9OyZct04cIFJScnq7KyUpmZmbrnnnuUkJCghQsXNkWPAAAAYRfymqbExETt2rVLH330kQ4cOKC6ujr9zd/8jQYPHtwU/QEAAESEkELT1atX1aJFCx08eFAPPfSQHnrooabqCwAAIKKE9PJcTEyMunTpotra2qbqBwAAICKFvKbp+eefD9oJHAAA4HYQ8pqml19+WX/84x+VmpqqLl26qFWrVkHjBw4caLTmAAAAIkXIoWn06NFyuVxN0QsAAEDECjk0zZs3rwnaAAAAiGzWa5q++uorTZ06VR07dlRycrKysrJ08eLFpuwNAAAgYliHprlz52rdunUaMWKExo0bp+3bt+upp55qyt4AAAAihvXLc++8845ee+01jRs3TpI0YcIEDRgwQLW1tYqOjm6yBgEAACKB9UzTqVOn9KMf/ci5/4Mf/EAxMTE6e/ZskzQGAAAQSaxDU21treLi4oKOxcTE6OrVq43eFAAAQKSxfnnOGKOf/exncrvdzrErV67oySefDNqr6Z133mncDgEAACKAdWh67LHH6h2bMGFCozYDAAAQqaxD0+uvv96UfQAAAES0kD97DgAA4HZEaAIAALBAaAIAALBAaAIAALBAaAIAALBAaAIAALBAaAIAALBAaAIAALBAaAIAALBgvSM4bi9RV/zhbgEAEOFut+eKsIamefPmaf78+UHHUlJSVF5eLunrDwmeP3++8vPz5fP5lJGRoVWrVqlHjx5OfVVVlfLy8rRx40ZVVlZq0KBBevXVV3XHHXc4NT6fT9OmTdN7770nSRo1apReeeUVtW7d2qk5efKkpk6dqo8++kjx8fHKysrSsmXLFBcX14Q/gcjj8XgUG+eWPtsR7lYAALeA2Di3PB5PuNv4ToR9pqlHjx768MMPnfvR0dHO10uXLtXy5cu1bt06paena8GCBRoyZIhKS0uVkJAgScrNzdWWLVtUUFCgtm3baubMmRo5cqSKi4ud75WVlaXTp0+rsLBQkjRlyhRlZ2dry5YtkqTa2lqNGDFC7du3165du/SnP/1Jjz32mIwxeuWVV76rH0VESElJ0ZtvrJfff3v99gB8kxMnTmjhwoV67rnn1KVLl3C3A0QMj8ejlJSUcLfx3TBhNHfuXPNXf/VXDY7V1dUZr9drlixZ4hy7cuWK8Xg8Zs2aNcYYYyoqKkxsbKwpKChwas6cOWOioqJMYWGhMcaYw4cPG0lmz549Tk1RUZGRZI4cOWKMMWbr1q0mKirKnDlzxqnZuHGjcbvdxu/3W1+P3+83kkJ6DIBbQ2lpqcnMzDSlpaXhbgVAI7N9/g77QvBjx44pNTVVXbt21bhx4/TZZ59Jko4fP67y8nINHTrUqXW73crMzNTu3bslScXFxaqpqQmqSU1NVc+ePZ2aoqIieTweZWRkODV9+/aVx+MJqunZs6dSU1OdmmHDhqmqqkrFxcVNd/EAAOCWEdaX5zIyMrR+/Xqlp6fr3LlzWrBggfr3769Dhw4565qun/JLSUnRiRMnJEnl5eWKi4tTUlJSvZprjy8vL1dycnK9cycnJwfVXH+epKQkxcXFOTUNqaqqUlVVlXM/EAjYXjoAALjFhDU0DR8+3Pm6V69e6tevn+6++279x3/8h/r27StJcrlcQY8xxtQ7dr3raxqq/zY111u8eHG9hewAAKB5CvvLc3+uVatW6tWrl44dOyav1ytJ9WZ6zp8/78wKeb1eVVdXy+fz3bTm3Llz9c514cKFoJrrz+Pz+VRTU3PTxW1z5syR3+93bqdOnQrxigEAwK0iokJTVVWV/vCHP6hDhw7q2rWrvF6vtm/f7oxXV1drx44d6t+/vySpT58+io2NDaopKytTSUmJU9OvXz/5/X7t27fPqdm7d6/8fn9QTUlJicrKypyabdu2ye12q0+fPjfs1+12KzExMegGAACap7C+PJeXl6dHHnlEnTt31vnz57VgwQIFAgE99thjcrlcys3N1aJFi5SWlqa0tDQtWrRILVu2VFZWlqSv3+Y4adIkzZw5U23btlWbNm2Ul5enXr16afDgwZKk++67Tw8//LAmT56stWvXSvp6y4GRI0eqW7dukqShQ4eqe/fuys7O1osvvqhLly4pLy9PkydPJggBAABJYQ5Np0+f1j/8wz/o4sWLat++vfr27as9e/Y4e6DMnj1blZWVysnJcTa33LZtm7NHkyStWLFCMTExGjt2rLO55bp164L2e9qwYYOmTZvmvMtu1KhRWrlypTMeHR2t999/Xzk5ORowYEDQ5pYAAACS5DLGmHA30VwEAgF5PB75/X5mqIBm5ujRo5oyZYry8/OVnp4e7nYANCLb5++IWtMEAAAQqQhNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFghNAAAAFiImNC1evFgul0u5ubnOMWOM5s2bp9TUVMXHx2vgwIE6dOhQ0OOqqqr09NNPq127dmrVqpVGjRql06dPB9X4fD5lZ2fL4/HI4/EoOztbFRUVQTUnT57UI488olatWqldu3aaNm2aqqurm+pyAQDALSYiQtP+/fuVn5+v3r17Bx1funSpli9frpUrV2r//v3yer0aMmSILl++7NTk5uZq8+bNKigo0K5du/TFF19o5MiRqq2tdWqysrJ08OBBFRYWqrCwUAcPHlR2drYzXltbqxEjRujLL7/Url27VFBQoE2bNmnmzJlNf/EAAODWYMLs8uXLJi0tzWzfvt1kZmaa6dOnG2OMqaurM16v1yxZssSpvXLlivF4PGbNmjXGGGMqKipMbGysKSgocGrOnDljoqKiTGFhoTHGmMOHDxtJZs+ePU5NUVGRkWSOHDlijDFm69atJioqypw5c8ap2bhxo3G73cbv91tfi9/vN5JCegyAW0NpaanJzMw0paWl4W4FQCOzff4O+0zT1KlTNWLECA0ePDjo+PHjx1VeXq6hQ4c6x9xutzIzM7V7925JUnFxsWpqaoJqUlNT1bNnT6emqKhIHo9HGRkZTk3fvn3l8XiCanr27KnU1FSnZtiwYaqqqlJxcfENe6+qqlIgEAi6AQCA5ikmnCcvKCjQgQMHtH///npj5eXlkqSUlJSg4ykpKTpx4oRTExcXp6SkpHo11x5fXl6u5OTket8/OTk5qOb68yQlJSkuLs6pacjixYs1f/78b7pMAADQDIRtpunUqVOaPn263nzzTbVo0eKGdS6XK+i+MabesetdX9NQ/bepud6cOXPk9/ud26lTp27aFwAAuHWFLTQVFxfr/Pnz6tOnj2JiYhQTE6MdO3bo5ZdfVkxMjDPzc/1Mz/nz550xr9er6upq+Xy+m9acO3eu3vkvXLgQVHP9eXw+n2pqaurNQP05t9utxMTEoBsAAGiewhaaBg0apP/5n//RwYMHndsDDzyg8ePH6+DBg7rrrrvk9Xq1fft25zHV1dXasWOH+vfvL0nq06ePYmNjg2rKyspUUlLi1PTr109+v1/79u1zavbu3Su/3x9UU1JSorKyMqdm27Ztcrvd6tOnT5P+HAAAwK0hbGuaEhIS1LNnz6BjrVq1Utu2bZ3jubm5WrRokdLS0pSWlqZFixapZcuWysrKkiR5PB5NmjRJM2fOVNu2bdWmTRvl5eWpV69ezsLy++67Tw8//LAmT56stWvXSpKmTJmikSNHqlu3bpKkoUOHqnv37srOztaLL76oS5cuKS8vT5MnT2b2CAAASArzQvBvMnv2bFVWVionJ0c+n08ZGRnatm2bEhISnJoVK1YoJiZGY8eOVWVlpQYNGqR169YpOjraqdmwYYOmTZvmvMtu1KhRWrlypTMeHR2t999/Xzk5ORowYIDi4+OVlZWlZcuWfXcXCwAAIprLGGPC3URzEQgE5PF45Pf7maECmpmjR49qypQpys/PV3p6erjbAdCIbJ+/w75PEwAAwK2A0AQAAGCB0AQAAGCB0AQAAGCB0AQAAGCB0AQAAGCB0AQAAGCB0AQAAGCB0AQAAGCB0AQAAGCB0AQAAGCB0AQAAGCB0AQAAGCB0AQAAGCB0AQAAGCB0AQAAGAhJtwNAGjYlStXdPLkyXC3gf9z4sSJoD8Rfp07d1aLFi3C3QZuI4QmIEKdPHlSU6ZMCXcbuM7ChQvD3QL+T35+vtLT08PdBm4jhCYgQnXu3Fn5+fnhbgOIWJ07dw53C7jNEJqACNWiRQt+iwaACMJCcAAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAuEJgAAAAsx4W6gOTHGSJICgUCYOwEAALauPW9fex6/EUJTI7p8+bIkqVOnTmHuBAAAhOry5cvyeDw3HHeZb4pVsFZXV6ezZ88qISFBLpcr3O0AaESBQECdOnXSqVOnlJiYGO52ADQiY4wuX76s1NRURUXdeOUSoQkALAQCAXk8Hvn9fkITcJtiITgAAIAFQhMAAIAFQhMAWHC73Zo7d67cbne4WwEQJqxpAgAAsMBMEwAAgAVCEwAAgAVCEwAAgAVCEwAAgAVCEwAAgAVCEwAAgAVCEwAAgAVCEwAAgIX/Bayz4YUj0UAGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating plot box plot for detection of outliers using seaborn\n",
    "sns.boxplot(df['Previous CTC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57b79048-83da-485a-95e3-86145382eac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Graduation Marks'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df['Graduation Marks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e93b2b66-070e-41e8-b47c-66790feed954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='EXP (Month)'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df['EXP (Month)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "643b273f-bdb3-4515-af0c-ad108ec192dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='CTC'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAGLCAYAAAAF7dxzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7c0lEQVR4nO3dfXSU5YH+8SsJyRBi8pAAyTAKSD1AhSDauIVAJbRCwBJoXStqaBZaG1BAmpr8VIoVdAV8xbYgIp4esUrJdhfjlooxYF1YSgIYSSGgYFskvCSEwjABzBvJ/fuD8iyTAEJ4ZDLJ93POnCbPfc3MPdNj5uKeZ+4JMcYYAQAA4IqFBnoCAAAAbQXFCgAAwCEUKwAAAIdQrAAAABxCsQIAAHAIxQoAAMAhFCsAAACHdAj0BNqbxsZGHTp0SNHR0QoJCQn0dAAAwCUwxujEiRPyeDwKDb3wuhTF6io7dOiQevToEehpAACAFti/f7+uu+66C45TrK6y6OhoSWf+j4mJiQnwbAAAwKWoqqpSjx497NfxC6FYXWVn3/6LiYmhWAEAEGS+7DQeTl4HAABwCMUKAADAIRQrAAAAh1CsAAAAHEKxAgAAcAjFCgAAwCEUKwAAAIdQrAAAABxCsQIAAHAIO68DgAMaGhq0fft2HTt2THFxcbrpppsUFhYW6GkBuMooVgBwhTZs2KAlS5aooqLCPuZ2uzVt2jQNHz48gDMDcLXxViAAXIENGzZozpw5+trXvqaXX35Za9as0csvv6yvfe1rmjNnjjZs2BDoKQK4ikKMMSbQk2hPqqqqZFmWfD4fX8IMBLmGhgZNnDhRX/va1/T0008rNPT//q3a2Nioxx9/XHv37tVbb73F24JAkLvU129WrACghbZv366KigpNnDjRr1RJUmhoqCZOnKjy8nJt3749QDMEcLVRrACghY4dOyZJ6t2793nHzx4/mwPQ9lGsAKCF4uLiJEl79+497/jZ42dzANo+ihUAtNBNN90kt9utFStWqLGx0W+ssbFRK1asUPfu3XXTTTcFaIYArjaKFQC0UFhYmKZNm6bCwkI9/vjj2rlzp7744gvt3LlTjz/+uAoLC/Xggw9y4jrQjvCpwKuMTwUCbc/59rHq3r27HnzwQfaxAtqIS339ZoNQALhCw4cP15AhQ/Tf//3fOnTokDwej773ve8pIiIi0FMDcJVRrADgCp1vxWrVqlXsvA60Q5xjBQBXgJ3XAZyLc6yuMs6xAtoOdl4H2g92XgeArxg7rwNoimIFAC3EzusAmqJYAUALsfM6gKYoVgDQQuy8DqCpgBarDRs2aNy4cfJ4PAoJCdE777xjj9XX1+vRRx/VwIEDFRUVJY/Ho3/7t3/ToUOH/G6jtrZWDz30kLp27aqoqCiNHz9eBw4c8Mt4vV5lZGTIsixZlqWMjAwdP37cL1NWVqZx48YpKipKXbt21cyZM1VXV+eX2bFjh1JSUhQZGalrr71WTz31lDj3H2i/zt15ffbs2crLy9OaNWuUl5en2bNns/M60A4FdB+rU6dOadCgQfrRj36ku+66y2/siy++0Mcff6xf/OIXGjRokLxer7KysjR+/Hh99NFHdi4rK0urV69Wbm6uunTpouzsbKWlpam4uNj+Y5aenq4DBw4oPz9fkjRlyhRlZGRo9erVks58smfs2LHq1q2bNm7cqKNHj2rSpEkyxmjRokWSznwaYNSoUfr2t7+trVu3as+ePZo8ebKioqKUnZ19NZ4uAK3Q8OHDdc899+g///M/VVhYaB8PCwvTPffcwz5WQHtjWglJJi8v76KZLVu2GElm3759xhhjjh8/bsLDw01ubq6dOXjwoAkNDTX5+fnGGGN27dplJJmioiI7U1hYaCSZTz/91BhjzJo1a0xoaKg5ePCgnVm5cqVxuVzG5/MZY4xZsmSJsSzL1NTU2JkFCxYYj8djGhsbLzjnmpoa4/P57Mv+/fuNJPt2AQS39evXmxEjRpjHHnvMvP3222bNmjXm7bffNo899pgZMWKEWb9+faCnCMABPp/vkl6/g+ocK5/Pp5CQEHXu3FmSVFxcrPr6eqWmptoZj8ejxMREbdq0SZJUWFgoy7I0ePBgOzNkyBBZluWXSUxMlMfjsTOjR49WbW2tiouL7UxKSopcLpdf5tChQ/r8888vOOcFCxbYb0FalqUePXpc8fMAoHVoaGjQkiVLlJycrHnz5unOO+/UHXfcoTvvvFPz5s1TcnKyXnnlFTU0NAR6qgCukqApVjU1NXrssceUnp5ub8xVUVGhiIgIxcbG+mUTEhLsr5aoqKhQfHx8s9uLj4/3yyQkJPiNx8bGKiIi4qKZs7+f+zUWTc2aNUs+n8++7N+//3IeNoBWjH2sADQVFN8VWF9fr3vvvVeNjY1asmTJl+aNMQoJCbF/P/dnJzPmnyeun++6Z7lcLr9VLgBtx7n7WNXV1TX7Emb2sQLan1ZfrOrr6zVhwgTt3btXf/rTn/y2kXe73aqrq5PX6/VbtaqsrNTQoUPtzOHDh5vd7pEjR+wVJ7fbrc2bN/uNe71e1dfX+2WarkxVVlZKUrOVLADtw9n9qRYuXKgPP/zQ7y2/pUuXasSIEX45AG1fq34r8Gyp+uyzz7Ru3Tp16dLFbzwpKUnh4eFau3atfay8vFylpaV2sUpOTpbP59OWLVvszObNm+Xz+fwypaWlKi8vtzMFBQVyuVxKSkqyMxs2bPDbgqGgoEAej0fXX3+9448dQOt30003qVOnTlq3bp1iYmKUk5OjVatWKScnRzExMfrggw8UFRXFPlZAOxLQYnXy5EmVlJSopKRE0pldiktKSlRWVqbTp0/rBz/4gT766COtWLFCDQ0NqqioUEVFhV1uLMvS/fffr+zsbH3wwQfatm2bfvjDH2rgwIEaOXKkJOnGG2/UmDFjlJmZqaKiIhUVFSkzM1NpaWnq16+fJCk1NVX9+/dXRkaGtm3bpg8++EA5OTnKzMy0V8jS09Plcrk0efJklZaWKi8vT/Pnz9fDDz980bcCAbRdDQ0NqqmpkST169dPvXv3VmRkpHr37m3/famurubkdaA9uQqfULygDz/80Ehqdpk0aZLZu3fvecckmQ8//NC+jerqajNjxgwTFxdnIiMjTVpamikrK/O7n6NHj5qJEyea6OhoEx0dbSZOnGi8Xq9fZt++fWbs2LEmMjLSxMXFmRkzZvhtrWCMMdu3bze33Xabcblcxu12m7lz5150q4XzudSPawJo/X7/+9+blJQU8+KLL5p77rnHpKSk2Jd7773XvPjiiyYlJcX8/ve/D/RUAVyhS339DjGGrcOvpqqqKlmWJZ/P53e+GIDg86tf/Up5eXlatWqVOnfurO3bt+vYsWOKi4vTTTfdJK/Xqx/84Ae688479dOf/jTQ0wVwBS719btVn2MFAK3Z2b3vzt1x/Vxnj5+7Rx6Ato0Vq6uMFSug7airq9Mdd9yhjh076pprrvH7BHJCQoJOnjypmpoavffee4qIiAjgTAFcKVasAOArFhERoSFDhujUqVPNtnU5fPiwTp06pSFDhlCqgHaEYgUALdTQ0KCdO3deNLNr1y4+FQi0IxQrAGihkpISHT9+XAMHDlR+fr6mT5+uO++8U9OnT1d+fr4GDhwor9drbykDoO1r9TuvA0BrdbYwTZ48WR07dtTdd9/tNz558mRlZ2erpKTE3mwYQNvGihUAXCE2CQZwFsUKAFro5ptvliS9/vrramxs9BtrbGzU8uXL/XIA2j6KFQC00M0336zOnTtrx44dmj17tnbu3KkvvvhCO3fu1OzZs7Vjxw517tyZYgW0I5xjBQAtFBYWpocfflhPPPGEPv74Y7+NQl0ulyTp4YcfVlhYWKCmCOAqY8UKAK7A8OHD9dRTT6lz585+x2NjY/XUU09p+PDhgZkYgIBgxQoArtDw4cP1jW98QwsWLNChQ4fk8Xg0a9YsXXPNNYGeGoCrjGIFAFdo9uzZ+vOf/2z/vnfvXqWlpWnYsGGaN29eAGcG4GrjrUAAuAJNS9W5/vznP2v27NlXeUYAAokVKwBooerqartUDRkyRBkZGerdu7f27t2rN998U0VFRfrzn/+s6upqRUZGBni2AK4GVqwAoIVeeeUVSdK1116r+fPna8CAAerUqZMGDBig+fPny+Px+OUAtH0UKwBood27d0uSMjMzFRrq/+c0NDRUP/nJT/xyANo+ihUAtNDZT/3t3LlTDQ0N2rZtmz744ANt27ZNDQ0N2rVrl18OQNvHOVYA0EITJkxQcXGxVq1apfXr16uystIei4+P1z/+8Q87B6B9YMUKAFro1ltvVYcOHdTY2OhXqiSpsrJSjY2N6tChg2699dYAzRDA1UaxAoArEBERcUXjANoWihUAtFBJSYm++OILRUdHn3c8OjpaX3zxhUpKSq7uxAAEDMUKAFrobGE6ceKErrnmGsXExMjlcikmJkbXXHONTpw44ZcD0PZx8joAtFBDQ4P988mTJ+2fa2trL5gD0LaxYgUALXRumZKkXr16aeLEierVq9dFcwDaLlasAKCF6uvr7Z/DwsK0b98+7du3z/797ErVuTkAbRsrVgDQQkVFRfbPTd/uO/f3c3MA2jaKFQC00OnTpx3NAQh+FCsAaKFOnTo5mgMQ/ChWANBC3/rWtxzNAQh+FCsAaKHjx4/7/W5Zlm644QZZlnXRHIC2i08FAkALeb1eSVJISIiMMfL5fPL5fPb42eNncwDaPlasAKCFIiMjJUnGmPOOnz1+Ngeg7aNYAUALDRw40NEcgOBHsQKAFurdu7ejOQDBj2IFAC20Y8cOR3MAgl9Ai9WGDRs0btw4eTwehYSE6J133vEbf/vttzV69Gh17dpVISEh5/2G+NraWj300EPq2rWroqKiNH78eB04cMAv4/V6lZGRIcuyZFmWMjIymn1Kp6ysTOPGjVNUVJS6du2qmTNnqq6uzi+zY8cOpaSkKDIyUtdee62eeuqpC55bAaDtO3TokKM5AMEvoMXq1KlTGjRokBYvXnzB8WHDhumZZ5654G1kZWUpLy9Pubm52rhxo06ePKm0tDS/r5NIT09XSUmJ8vPzlZ+fr5KSEmVkZNjjDQ0NGjt2rE6dOqWNGzcqNzdXq1atUnZ2tp2pqqrSqFGj5PF4tHXrVi1atEgvvPCCFi5c6MAzASAY7d+/X5IUHh6uNWvWaPr06brzzjs1ffp0rVmzRh06dPDLAWgHTCshyeTl5Z13bO/evUaS2bZtm9/x48ePm/DwcJObm2sfO3jwoAkNDTX5+fnGGGN27dplJJmioiI7U1hYaCSZTz/91BhjzJo1a0xoaKg5ePCgnVm5cqVxuVzG5/MZY4xZsmSJsSzL1NTU2JkFCxYYj8djGhsbL/lx+nw+I8m+XQDBa+LEiSYlJcWkpKSYxx57zJSWlppTp06Z0tJS89hjj9ljEydODPRUAVyhS339DupzrIqLi1VfX6/U1FT7mMfjUWJiojZt2iRJKiwslGVZGjx4sJ0ZMmSILMvyyyQmJsrj8diZ0aNHq7a2VsXFxXYmJSVFLpfLL3Po0CF9/vnnF5xjbW2tqqqq/C4A2ob4+Hj7561bt2r69On67ne/q+nTp+ujjz46bw5A2xbUxaqiokIRERGKjY31O56QkKCKigo7c74/avHx8X6ZhIQEv/HY2FhFRERcNHP297OZ81mwYIF9bpdlWerRo8dlPkoArdU999xj/9z0i5br6+vPmwPQtgV1sboQY4xCQkLs38/92cmM+eeJ6+e77lmzZs2yd2P2+XycawG0IbfeeutF//uXzvx9uPXWW6/SjAAEWlAXK7fbrbq6umZfF1FZWWmvJrndbh0+fLjZdY8cOeKXabrq5PV6VV9ff9FMZWWlJDVbyTqXy+VSTEyM3wVA21BXV/elnww2xjT7hDGAtiuoi1VSUpLCw8O1du1a+1h5eblKS0s1dOhQSVJycrJ8Pp+2bNliZzZv3iyfz+eXKS0tVXl5uZ0pKCiQy+VSUlKSndmwYYPfH8iCggJ5PB5df/31X+XDBNBKvfLKK47mAAS/gH4J88mTJ/XXv/7V/n3v3r0qKSlRXFycevbsqWPHjqmsrMzeA2b37t2Szqweud1uWZal+++/X9nZ2erSpYvi4uKUk5OjgQMHauTIkZKkG2+8UWPGjFFmZqZeffVVSdKUKVOUlpamfv36SZJSU1PVv39/ZWRk6Pnnn9exY8eUk5OjzMxMe4UpPT1dTz75pCZPnqyf//zn+uyzzzR//nw98cQTX/pWAIC26ZNPPrF/jo2NtbdkOXTokNauXWuvpp+bA9DGfeWfT7yIDz/80Ehqdpk0aZIxxpjXX3/9vONz5syxb6O6utrMmDHDxMXFmcjISJOWlmbKysr87ufo0aNm4sSJJjo62kRHR5uJEycar9frl9m3b58ZO3asiYyMNHFxcWbGjBl+WysYY8z27dvNbbfdZlwul3G73Wbu3LmXtdWCMWy3ALQl9913n0lJSTHf+c53TE1Njfn444/NunXrzMcff2xqamrMd77zHZOSkmLuu+++QE8VwBW61NfvEGPYOvxqqqqqkmVZ8vl8nG8FBLlJkyZp3759CgkJUbdu3ezzLqUznzw+cuSIjDHq1auX3njjjQDOFMCVutTX76A+xwoAAik6OlrSmRPUjxw5olGjRum1117TqFGj7FJ1bg5A2xfQc6wAIJgNHTpUpaWlks6Uq7Vr1/p9mObcHID2gRUrAGihPn36OJoDEPwoVgDQQpf6FVV8lRXQflCsAKCF4uLiHM0BCH4UKwBoId4KBNAUxQoAWmjp0qWO5gAEP4oVALRQUVGRozkAwY9iBQAtdO53h4aG+v85Pfd3voQZaD/YxwoAWqhbt272J/6+8Y1vqFevXqqrq1NERIT27dunjz76yM4BaB8oVgDQQtdcc43980cffWQXqYvlALRtvBUIAC3U0NDgaA5A8KNYAUALXepbfLwVCLQfFCsAaKGoqChHcwCCH8UKAFroH//4h6M5AMGPYgUALUSxAtAUxQoAWuj06dOSmu9hddbZ42dzANo+ihUAtNDZbRQaGxvPO372ONstAO0HxQoAWmjo0KGO5gAEP4oVALRQr169HM0BCH4UKwBooVWrVjmaAxD8KFYA0EIVFRWO5gAEP4oVALRQdXW1ozkAwY9iBQAtVFNT42gOQPCjWAFAC9XV1TmaAxD8KFYA0EIRERGO5gAEP4oVALRQTEyMozkAwY9iBQAtZIxxNAcg+FGsAKCFeCsQQFMUKwBooejoaEdzAIIfxQoAWuhSv1yZL2EG2g+KFQC00N69ex3NAQh+FCsAaCF2XgfQVIdATwAAglVISIj9s2VZuv7662WMUUhIiD7//HP5fL5mOQBtG8UKAFqoU6dOOnnypCTJ5/PpL3/5ywVzANoHihUQxGpqalRWVhboabRb0dHRqqysvKTcnj17rsKM0FTPnj3VsWPHQE8D7UiIYee6q6qqqkqWZcnn87EbM67Ynj17NGXKlEBPA2i1li1bpr59+wZ6GmgDLvX1O6ArVhs2bNDzzz+v4uJilZeXKy8vT9///vftcWOMnnzySS1btkxer1eDBw/Wyy+/rAEDBtiZ2tpa5eTkaOXKlaqurtbtt9+uJUuW6LrrrrMzXq9XM2fO1B/+8AdJ0vjx47Vo0SJ17tzZzpSVlWn69On605/+pMjISKWnp+uFF17w29hvx44dmjFjhrZs2aK4uDhNnTpVv/jFLzh/AgHTs2dPLVu2LNDTaLdOnz6tadOmfWluyZIl6tCBNwgCoWfPnoGeAtqZgP6XfurUKQ0aNEg/+tGPdNdddzUbf+6557Rw4UItX75cffv21dNPP61Ro0Zp9+7d9oZ7WVlZWr16tXJzc9WlSxdlZ2crLS1NxcXFCgsLkySlp6frwIEDys/PlyRNmTJFGRkZWr16tSSpoaFBY8eOVbdu3bRx40YdPXpUkyZNkjFGixYtknSmqY4aNUrf/va3tXXrVu3Zs0eTJ09WVFSUsrOzr8bTBTTTsWNH/jUeYPfee69yc3MvOt6/f/+rOCMAAWVaCUkmLy/P/r2xsdG43W7zzDPP2MdqamqMZVlm6dKlxhhjjh8/bsLDw01ubq6dOXjwoAkNDTX5+fnGGGN27dplJJmioiI7U1hYaCSZTz/91BhjzJo1a0xoaKg5ePCgnVm5cqVxuVzG5/MZY4xZsmSJsSzL1NTU2JkFCxYYj8djGhsbL/lx+nw+I8m+XQDB75VXXjEjRowwKSkp9mXEiBHmlVdeCfTUADjkUl+/W+0+Vnv37lVFRYVSU1PtYy6XSykpKdq0aZMkqbi4WPX19X4Zj8ejxMREO1NYWCjLsjR48GA7M2TIEFmW5ZdJTEyUx+OxM6NHj1Ztba2Ki4vtTEpKilwul1/m0KFD+vzzzy/4OGpra1VVVeV3AdC2PPDAA3r//fc1YcIESdKECRP0/vvv64EHHgjwzABcba22WFVUVEiSEhIS/I4nJCTYYxUVFYqIiFBsbOxFM/Hx8c1uPz4+3i/T9H5iY2MVERFx0czZ389mzmfBggWyLMu+9OjR4+IPHEBQioiI0MiRIyVJI0eO5IuXgXaq1Rars5qeGG7+ufnexTTNnC/vRMb88wOVF5vPrFmz5PP57Mv+/fsvOncAABC8Wm2xcrvdkpqvBlVWVtorRW63W3V1dfJ6vRfNHD58uNntHzlyxC/T9H68Xq/q6+svmjm7f03TlaxzuVwuxcTE+F0AAEDb1GqLVe/eveV2u7V27Vr7WF1dndavX6+hQ4dKkpKSkhQeHu6XKS8vV2lpqZ1JTk6Wz+fTli1b7MzmzZvl8/n8MqWlpSovL7czBQUFcrlcSkpKsjMbNmxQXV2dX8bj8ej66693/gkAAABBJ6DF6uTJkyopKVFJSYmkMyesl5SUqKysTCEhIcrKytL8+fOVl5en0tJSTZ48WZ06dVJ6erqkM9/Ndf/99ys7O1sffPCBtm3bph/+8IcaOHCgfa7DjTfeqDFjxigzM1NFRUUqKipSZmam0tLS1K9fP0lSamqq+vfvr4yMDG3btk0ffPCBcnJylJmZaa8wpaeny+VyafLkySotLVVeXp7mz5+vhx9+mH2sAADAGV/9BxQv7MMPPzSSml0mTZpkjDmz5cKcOXOM2+02LpfLDB8+3OzYscPvNqqrq82MGTNMXFyciYyMNGlpaaasrMwvc/ToUTNx4kQTHR1toqOjzcSJE43X6/XL7Nu3z4wdO9ZERkaauLg4M2PGDL+tFYwxZvv27ea2224zLpfLuN1uM3fu3MvaasEYtlsA2rLdu3eblJQUs3v37kBPBYDDLvX1m6+0ucr4Shug7Tr7FUN8jQrQ9lzq63erPccKAAAg2FCsAAAAHEKxAgAAcAjFCgAAwCEUKwAAAIdQrAAAABxCsQIAAHAIxQoAAMAhFCsAAACHUKwAAAAcQrECAABwCMUKAADAIRQrAAAAh1CsAAAAHEKxAgAAcAjFCgAAwCEUKwAAAIdQrAAAABxCsQIAAHAIxQoAAMAhFCsAAACHUKwAAAAcQrECAABwCMUKAADAIRQrAAAAh1CsAAAAHEKxAgAAcAjFCgAAwCEUKwAAAIdQrAAAABxCsQIAAHAIxQoAAMAhFCsAAACHUKwAAAAcQrECAABwCMUKAADAIRQrAAAAh7T6YnXixAllZWWpV69eioyM1NChQ7V161Z73BijuXPnyuPxKDIyUiNGjNDOnTv9bqO2tlYPPfSQunbtqqioKI0fP14HDhzwy3i9XmVkZMiyLFmWpYyMDB0/ftwvU1ZWpnHjxikqKkpdu3bVzJkzVVdX95U9dgAAEFwuq1h5vV4tWrRIVVVVzcZ8Pt8Fx67ET37yE61du1ZvvvmmduzYodTUVI0cOVIHDx6UJD333HNauHChFi9erK1bt8rtdmvUqFE6ceKEfRtZWVnKy8tTbm6uNm7cqJMnTyotLU0NDQ12Jj09XSUlJcrPz1d+fr5KSkqUkZFhjzc0NGjs2LE6deqUNm7cqNzcXK1atUrZ2dmOPl4AABDEzGV46qmnzA9+8IMLjt99993m6aefvpybvKgvvvjChIWFmT/+8Y9+xwcNGmRmz55tGhsbjdvtNs8884w9VlNTYyzLMkuXLjXGGHP8+HETHh5ucnNz7czBgwdNaGioyc/PN8YYs2vXLiPJFBUV2ZnCwkIjyXz66afGGGPWrFljQkNDzcGDB+3MypUrjcvlMj6f75Ifk8/nM5Iu6zoAgsPu3btNSkqK2b17d6CnAsBhl/r6fVkrVqtWrdIDDzxwwfGpU6fqv/7rv66o6J3r9OnTamhoUMeOHf2OR0ZGauPGjdq7d68qKiqUmppqj7lcLqWkpGjTpk2SpOLiYtXX1/tlPB6PEhMT7UxhYaEsy9LgwYPtzJAhQ2RZll8mMTFRHo/HzowePVq1tbUqLi6+4GOora1VVVWV3wUAALRNl1Ws/va3v6lPnz4XHO/Tp4/+9re/XfGkzoqOjlZycrL+/d//XYcOHVJDQ4Peeustbd68WeXl5aqoqJAkJSQk+F0vISHBHquoqFBERIRiY2MvmomPj292//Hx8X6ZpvcTGxuriIgIO3M+CxYssM/bsixLPXr0uMxnAQAABIvLKlZhYWE6dOjQBccPHTqk0FBnz4d/8803ZYzRtddeK5fLpV//+tdKT09XWFiYnQkJCfG7jjGm2bGmmmbOl29JpqlZs2bJ5/PZl/379190XgAAIHhdVgu65ZZb9M4771xwPC8vT7fccsuVzsnPDTfcoPXr1+vkyZPav3+/tmzZovr6evXu3Vtut1uSmq0YVVZW2qtLbrdbdXV18nq9F80cPny42X0fOXLEL9P0frxer+rr65utZJ3L5XIpJibG7wIAANqmyypWM2bM0IsvvqjFixf7faKuoaFBixYt0ksvvaTp06c7PklJioqKUvfu3eX1evX+++/re9/7nl2u1q5da+fq6uq0fv16DR06VJKUlJSk8PBwv0x5eblKS0vtTHJysnw+n7Zs2WJnNm/eLJ/P55cpLS1VeXm5nSkoKJDL5VJSUtJX8pgBAECQudyz4n/+85+bkJAQExMTY26++WZzyy23mJiYGBMaGmoeffTRlpxof1H5+fnmvffeM3//+99NQUGBGTRokPnmN79p6urqjDHGPPPMM8ayLPP222+bHTt2mPvuu890797dVFVV2bfxwAMPmOuuu86sW7fOfPzxx+Y73/mOGTRokDl9+rSdGTNmjLnppptMYWGhKSwsNAMHDjRpaWn2+OnTp01iYqK5/fbbzccff2zWrVtnrrvuOjNjxozLejx8KhBou/hUINB2Xerrd4fLKWG//e1v9cQTT+h73/ueVqxYob/+9a8yxmj48OFKT0/XN7/5TceLn8/n06xZs3TgwAHFxcXprrvu0rx58xQeHi5JeuSRR1RdXa1p06bJ6/Vq8ODBKigoUHR0tH0bL730kjp06KAJEyaourpat99+u5YvX+53ntaKFSs0c+ZM+9OD48eP1+LFi+3xsLAwvfvuu5o2bZqGDRumyMhIpaen64UXXnD8MQMAgOAUYowxlxoOCwtTeXn5eT9Bh0tTVVUly7Lk8/k43wpoY/bs2aMpU6Zo2bJl6tu3b6CnA8BBl/r6fVnnWF1GBwMAAGh3LntvhC/bxgAAAKC9uqxzrCRp8uTJcrlcF828/fbbLZ4QAABAsLrsYhUdHa3IyMivYi4AAABB7bKL1a9//WtOXgcAADiPyzrHivOrAAAALuyyPxVIuQIAADi/yypW69atU3JysqqqqpqN+Xw+DRgwQP/7v//r2OQAAACCyWUVq1/96leaPn36eTfGsixLU6dO1cKFCx2bHAAAQDC5rGK1bds2jRkz5oLjqampKi4uvuJJAQAABKPLKlaVlZX2d/SdT4cOHXTkyJErnhQAAEAwuqxide2112rHjh0XHN++fbu6d+9+xZMCAAAIRpdVrL773e/qiSeeUE1NTbOx6upqzZkzR2lpaY5NDgAAIJhc1gahjz/+uN5++2317dtXM2bMUL9+/RQSEqJPPvlEL7/8shoaGjR79uyvaq4AAACt2mUVq4SEBG3atEkPPvigZs2aJWOMpDMbh44ePVpLlixRQkLCVzJRAACA1u6yv9KmV69eWrNmjbxer/7617/KGKM+ffooNjb2q5gfAABA0LjsYnVWbGys/uVf/sXJuQAAAAS1yzp5HQAAABdGsQIAAHAIxQoAAMAhFCsAAACHUKwAAAAcQrECAABwCMUKAADAIRQrAAAAh1CsAAAAHEKxAgAAcAjFCgAAwCEUKwAAAIdQrAAAABxCsQIAAHAIxQoAAMAhFCsAAACHUKwAAAAcQrECAABwCMUKAADAIRQrAAAAh3QI9AQu5vTp05o7d65WrFihiooKde/eXZMnT9bjjz+u0NAzndAYoyeffFLLli2T1+vV4MGD9fLLL2vAgAH27dTW1ionJ0crV65UdXW1br/9di1ZskTXXXednfF6vZo5c6b+8Ic/SJLGjx+vRYsWqXPnznamrKxM06dP15/+9CdFRkYqPT1dL7zwgiIiIq7OE9KKHD58WD6fL9DTAFqVffv2+f0vgDMsy1JCQkKgp3FVtOpi9eyzz2rp0qV64403NGDAAH300Uf60Y9+JMuy9NOf/lSS9Nxzz2nhwoVavny5+vbtq6efflqjRo3S7t27FR0dLUnKysrS6tWrlZubqy5duig7O1tpaWkqLi5WWFiYJCk9PV0HDhxQfn6+JGnKlCnKyMjQ6tWrJUkNDQ0aO3asunXrpo0bN+ro0aOaNGmSjDFatGhRAJ6dwDl8+LB+mPFvqq+rDfRUgFZp3rx5gZ4C0KqER7j01pu/bRflKsQYYwI9iQtJS0tTQkKCfvOb39jH7rrrLnXq1ElvvvmmjDHyeDzKysrSo48+KunM6lRCQoKeffZZTZ06VT6fT926ddObb76pe+65R5J06NAh9ejRQ2vWrNHo0aP1ySefqH///ioqKtLgwYMlSUVFRUpOTtann36qfv366b333lNaWpr2798vj8cjScrNzdXkyZNVWVmpmJiY8z6G2tpa1db+XwGpqqpSjx495PP5Lnid1m7Pnj2aMmWKqr+WosaOVqCnAwBoxUJrfIr8+3otW7ZMffv2DfR0WqyqqkqWZX3p63erXrH61re+paVLl2rPnj3q27ev/vKXv2jjxo365S9/KUnau3evKioqlJqaal/H5XIpJSVFmzZt0tSpU1VcXKz6+nq/jMfjUWJiojZt2qTRo0ersLBQlmXZpUqShgwZIsuytGnTJvXr10+FhYVKTEy0S5UkjR49WrW1tSouLta3v/3t8z6GBQsW6Mknn3T4mWkdGjtaaozqGuhpAADQarTqYvXoo4/K5/Pp61//usLCwtTQ0KB58+bpvvvukyRVVFRIUrOlxYSEBPsch4qKCkVERCg2NrZZ5uz1KyoqFB8f3+z+4+Pj/TJN7yc2NlYRERF25nxmzZqlhx9+2P797IoVAABoe1p1sfqP//gPvfXWW/rd736nAQMGqKSkRFlZWfJ4PJo0aZKdCwkJ8bueMabZsaaaZs6Xb0mmKZfLJZfLddG5AACAtqFVb7fw//7f/9Njjz2me++9VwMHDlRGRoZ+9rOfacGCBZIkt9stSc1WjCorK+3VJbfbrbq6Onm93otmDh8+3Oz+jxw54pdpej9er1f19fXt4mQ8AADw5Vp1sfriiy/sbRXOCgsLU2NjoySpd+/ecrvdWrt2rT1eV1en9evXa+jQoZKkpKQkhYeH+2XKy8tVWlpqZ5KTk+Xz+bRlyxY7s3nzZvl8Pr9MaWmpysvL7UxBQYFcLpeSkpIcfuQAACAYteq3AseNG6d58+apZ8+eGjBggLZt26aFCxfqxz/+saQzb81lZWVp/vz56tOnj/r06aP58+erU6dOSk9Pl3Rm74z7779f2dnZ6tKli+Li4pSTk6OBAwdq5MiRkqQbb7xRY8aMUWZmpl599VVJZ7ZbSEtLU79+/SRJqamp6t+/vzIyMvT888/r2LFjysnJUWZmZtB+ug8AADirVRerRYsW6Re/+IWmTZumyspKeTweTZ06VU888YSdeeSRR1RdXa1p06bZG4QWFBTYe1hJ0ksvvaQOHTpowoQJ9gahy5cvt/ewkqQVK1Zo5syZ9qcHx48fr8WLF9vjYWFhevfddzVt2jQNGzbMb4NQAAAAqZXvY9UWXeo+GK3Z2X2sTvUfz3YLAICLCj31D0Xt+kO72ceqVZ9jBQAAEEwoVgAAAA6hWAEAADiEYgUAAOAQihUAAIBDKFYAAAAOoVgBAAA4hGIFAADgEIoVAACAQyhWAAAADqFYAQAAOIRiBQAA4BCKFQAAgEMoVgAAAA6hWAEAADiEYgUAAOAQihUAAIBDKFYAAAAOoVgBAAA4hGIFAADgEIoVAACAQyhWAAAADqFYAQAAOIRiBQAA4BCKFQAAgEM6BHoCCF6h1ccDPQUAQCvX3l4rKFZosci9GwI9BQAAWhWKFVqsuvdwNUZ2DvQ0AACtWGj18Xb1D3GKFVqsMbKzGqO6BnoaAAC0Gpy8DgAA4BCKFQAAgEMoVgAAAA6hWAEAADiEYgUAAOAQihUAAIBDKFYAAAAOafXF6vrrr1dISEizy/Tp0yVJxhjNnTtXHo9HkZGRGjFihHbu3Ol3G7W1tXrooYfUtWtXRUVFafz48Tpw4IBfxuv1KiMjQ5ZlybIsZWRk6Pjx436ZsrIyjRs3TlFRUeratatmzpypurq6r/TxAwCA4NHqi9XWrVtVXl5uX9auXStJuvvuuyVJzz33nBYuXKjFixdr69atcrvdGjVqlE6cOGHfRlZWlvLy8pSbm6uNGzfq5MmTSktLU0NDg51JT09XSUmJ8vPzlZ+fr5KSEmVkZNjjDQ0NGjt2rE6dOqWNGzcqNzdXq1atUnZ29lV6JgAAQGvX6nde79atm9/vzzzzjG644QalpKTIGKNf/vKXmj17tv71X/9VkvTGG28oISFBv/vd7zR16lT5fD795je/0ZtvvqmRI0dKkt566y316NFD69at0+jRo/XJJ58oPz9fRUVFGjx4sCTptddeU3Jysnbv3q1+/fqpoKBAu3bt0v79++XxeCRJL774oiZPnqx58+YpJibmKj4rAACgNWr1K1bnqqur01tvvaUf//jHCgkJ0d69e1VRUaHU1FQ743K5lJKSok2bNkmSiouLVV9f75fxeDxKTEy0M4WFhbIsyy5VkjRkyBBZluWXSUxMtEuVJI0ePVq1tbUqLi6+4Jxra2tVVVXldwEAAG1TUBWrd955R8ePH9fkyZMlSRUVFZKkhIQEv1xCQoI9VlFRoYiICMXGxl40Ex8f3+z+4uPj/TJN7yc2NlYRERF25nwWLFhgn7dlWZZ69OhxGY8YAAAEk6AqVr/5zW90xx13+K0aSVJISIjf78aYZseaapo5X74lmaZmzZoln89nX/bv33/ReQEAgOAVNMVq3759WrdunX7yk5/Yx9xutyQ1WzGqrKy0V5fcbrfq6urk9Xovmjl8+HCz+zxy5Ihfpun9eL1e1dfXN1vJOpfL5VJMTIzfBQAAtE1BU6xef/11xcfHa+zYsfax3r17y+12258UlM6ch7V+/XoNHTpUkpSUlKTw8HC/THl5uUpLS+1McnKyfD6ftmzZYmc2b94sn8/nlyktLVV5ebmdKSgokMvlUlJS0lfzoAEAQFBp9Z8KlKTGxka9/vrrmjRpkjp0+L8ph4SEKCsrS/Pnz1efPn3Up08fzZ8/X506dVJ6erokybIs3X///crOzlaXLl0UFxennJwcDRw40P6U4I033qgxY8YoMzNTr776qiRpypQpSktLU79+/SRJqamp6t+/vzIyMvT888/r2LFjysnJUWZmJqtQAABAUpAUq3Xr1qmsrEw//vGPm4098sgjqq6u1rRp0+T1ejV48GAVFBQoOjrazrz00kvq0KGDJkyYoOrqat1+++1avny5wsLC7MyKFSs0c+ZM+9OD48eP1+LFi+3xsLAwvfvuu5o2bZqGDRumyMhIpaen64UXXvgKHzkAAAgmIcYYE+hJtCdVVVWyLEs+ny9oV7r27NmjKVOm6FT/8WqM6hro6QAAWrHQU/9Q1K4/aNmyZerbt2+gp9Nil/r6HTTnWAEAALR2FCsAAACHUKwAAAAcQrECAABwCMUKAADAIRQrAAAAh1CsAAAAHBIUG4SidQqt8QV6CgCAVq69vVZQrHDZLMtSeIRL+vv6QE8FABAEwiNcsiwr0NO4KihWuGwJCQl6683fyudrX/8KAb7Mvn37NG/ePM2ePVu9evUK9HSAVsOyLCUkJAR6GlcFxQotkpCQ0G7+IwEuV69evYL6qzsAtBwnrwMAADiEYgUAAOAQihUAAIBDKFYAAAAOoVgBAAA4hGIFAADgEIoVAACAQyhWAAAADqFYAQAAOIRiBQAA4BCKFQAAgEMoVgAAAA6hWAEAADiEYgUAAOAQihUAAIBDKFYAAAAOoVgBAAA4hGIFAADgEIoVAACAQyhWAAAADqFYAQAAOIRiBQAA4BCKFQAAgEMoVgAAAA6hWAEAADiEYgUAAOCQVl+sDh48qB/+8Ifq0qWLOnXqpJtvvlnFxcX2uDFGc+fOlcfjUWRkpEaMGKGdO3f63UZtba0eeughde3aVVFRURo/frwOHDjgl/F6vcrIyJBlWbIsSxkZGTp+/LhfpqysTOPGjVNUVJS6du2qmTNnqq6u7it77AAAILi06mLl9Xo1bNgwhYeH67333tOuXbv04osvqnPnznbmueee08KFC7V48WJt3bpVbrdbo0aN0okTJ+xMVlaW8vLylJubq40bN+rkyZNKS0tTQ0ODnUlPT1dJSYny8/OVn5+vkpISZWRk2OMNDQ0aO3asTp06pY0bNyo3N1erVq1Sdnb2VXkuAABAEDCt2KOPPmq+9a1vXXC8sbHRuN1u88wzz9jHampqjGVZZunSpcYYY44fP27Cw8NNbm6unTl48KAJDQ01+fn5xhhjdu3aZSSZoqIiO1NYWGgkmU8//dQYY8yaNWtMaGioOXjwoJ1ZuXKlcblcxufzXfJj8vl8RtJlXQdAcNi9e7dJSUkxu3fvDvRUADjsUl+/W/WK1R/+8AfdeuutuvvuuxUfH69bbrlFr732mj2+d+9eVVRUKDU11T7mcrmUkpKiTZs2SZKKi4tVX1/vl/F4PEpMTLQzhYWFsixLgwcPtjNDhgyRZVl+mcTERHk8HjszevRo1dbW+r012VRtba2qqqr8LgAAoG1q1cXq73//u1555RX16dNH77//vh544AHNnDlTv/3tbyVJFRUVkqSEhAS/6yUkJNhjFRUVioiIUGxs7EUz8fHxze4/Pj7eL9P0fmJjYxUREWFnzmfBggX2eVuWZalHjx6X8xQAAIAg0qqLVWNjo77xjW9o/vz5uuWWWzR16lRlZmbqlVde8cuFhIT4/W6MaXasqaaZ8+Vbkmlq1qxZ8vl89mX//v0XnRcAAAherbpYde/eXf379/c7duONN6qsrEyS5Ha7JanZilFlZaW9uuR2u1VXVyev13vRzOHDh5vd/5EjR/wyTe/H6/Wqvr6+2UrWuVwul2JiYvwuAACgbWrVxWrYsGHavXu337E9e/aoV69ekqTevXvL7XZr7dq19nhdXZ3Wr1+voUOHSpKSkpIUHh7ulykvL1dpaamdSU5Ols/n05YtW+zM5s2b5fP5/DKlpaUqLy+3MwUFBXK5XEpKSnL4kQMAgGDUIdATuJif/exnGjp0qObPn68JEyZoy5YtWrZsmZYtWybpzFtzWVlZmj9/vvr06aM+ffpo/vz56tSpk9LT0yVJlmXp/vvvV3Z2trp06aK4uDjl5ORo4MCBGjlypKQzq2BjxoxRZmamXn31VUnSlClTlJaWpn79+kmSUlNT1b9/f2VkZOj555/XsWPHlJOTo8zMTFahAADAGVfhE4pXZPXq1SYxMdG4XC7z9a9/3SxbtsxvvLGx0cyZM8e43W7jcrnM8OHDzY4dO/wy1dXVZsaMGSYuLs5ERkaatLQ0U1ZW5pc5evSomThxoomOjjbR0dFm4sSJxuv1+mX27dtnxo4dayIjI01cXJyZMWOGqampuazHw3YLQNvFdgtA23Wpr98hxhgT6HLXnlRVVcmyLPl8Pla6gDZmz549mjJlipYtW6a+ffsGejoAHHSpr9+t+hwrAACAYEKxAgAAcAjFCgAAwCEUKwAAAIdQrAAAABxCsQIAAHAIxQoAAMAhFCsAAACHUKwAAAAcQrECAABwCMUKAADAIRQrAAAAh1CsAAAAHEKxAgAAcAjFCgAAwCEUKwAAAIdQrAAAABxCsQIAAHAIxQoAAMAhFCsAAACHUKwAAAAcQrECAABwCMUKAADAIRQrAAAAh1CsAAAAHNIh0BMA0HI1NTUqKysL9DTwT/v27fP7XwRez5491bFjx0BPA+0IxQoIYmVlZZoyZUqgp4Em5s2bF+gp4J+WLVumvn37BnoaaEcoVkAQ69mzp5YtWxboaQCtVs+ePQM9BbQzFCsgiHXs2JF/jQNAK8LJ6wAAAA6hWAEAADiEYgUAAOAQihUAAIBDKFYAAAAOoVgBAAA4hGIFAADgEIoVAACAQ1p1sZo7d65CQkL8Lm632x43xmju3LnyeDyKjIzUiBEjtHPnTr/bqK2t1UMPPaSuXbsqKipK48eP14EDB/wyXq9XGRkZsixLlmUpIyNDx48f98uUlZVp3LhxioqKUteuXTVz5kzV1dV9ZY8dAAAEn1ZdrCRpwIABKi8vty87duywx5577jktXLhQixcv1tatW+V2uzVq1CidOHHCzmRlZSkvL0+5ubnauHGjTp48qbS0NDU0NNiZ9PR0lZSUKD8/X/n5+SopKVFGRoY93tDQoLFjx+rUqVPauHGjcnNztWrVKmVnZ1+dJwEAAAQH04rNmTPHDBo06LxjjY2Nxu12m2eeecY+VlNTYyzLMkuXLjXGGHP8+HETHh5ucnNz7czBgwdNaGioyc/PN8YYs2vXLiPJFBUV2ZnCwkIjyXz66afGGGPWrFljQkNDzcGDB+3MypUrjcvlMj6f76KPoaamxvh8Pvuyf/9+I+lLrwcAAFoPn893Sa/frX7F6rPPPpPH41Hv3r1177336u9//7skae/evaqoqFBqaqqddblcSklJ0aZNmyRJxcXFqq+v98t4PB4lJibamcLCQlmWpcGDB9uZIUOGyLIsv0xiYqI8Ho+dGT16tGpra1VcXHzR+S9YsMB+i9GyLPXo0eMKnxEAANBatepiNXjwYP32t7/V+++/r9dee00VFRUaOnSojh49qoqKCklSQkKC33USEhLssYqKCkVERCg2Nvaimfj4+Gb3HR8f75dpej+xsbGKiIiwMxcya9Ys+Xw++7J///7LeAYAAEAw6RDoCVzMHXfcYf88cOBAJScn64YbbtAbb7yhIUOGSJJCQkL8rmOMaXasqaaZ8+Vbkjkfl8sll8vldx1Jqqqquuj1AABA63H2dfvs6/iFtOpi1VRUVJQGDhyozz77TN///vclnVlN6t69u52prKy0V5fcbrfq6urk9Xr9Vq0qKys1dOhQO3P48OFm93XkyBG/29m8ebPfuNfrVX19fbOVrC9z9sR63hIEACD4nDhxQpZlXXA8qIpVbW2tPvnkE912223q3bu33G631q5dq1tuuUWSVFdXp/Xr1+vZZ5+VJCUlJSk8PFxr167VhAkTJEnl5eUqLS3Vc889J0lKTk6Wz+fTli1b9M1vflOStHnzZvl8Prt8JScna968eSovL7dLXEFBgVwul5KSki7rMXg8Hu3fv1/R0dFfutoFILhUVVWpR48e2r9/v2JiYgI9HQAOMsboxIkTfudbn0+I+bI1rQDKycnRuHHj1LNnT1VWVurpp5/W+vXrtWPHDvXq1UvPPvusFixYoNdff119+vTR/Pnz9T//8z/avXu3oqOjJUkPPvig/vjHP2r58uWKi4tTTk6Ojh49quLiYoWFhUk685bjoUOH9Oqrr0qSpkyZol69emn16tWSzmy3cPPNNyshIUHPP/+8jh07psmTJ+v73/++Fi1aFJgnB0CrU1VVJcuy5PP5KFZAO9WqV6wOHDig++67T//4xz/UrVs3DRkyREVFRerVq5ck6ZFHHlF1dbWmTZsmr9erwYMHq6CgwC5VkvTSSy+pQ4cOmjBhgqqrq3X77bdr+fLldqmSpBUrVmjmzJn2pwfHjx+vxYsX2+NhYWF69913NW3aNA0bNkyRkZFKT0/XCy+8cJWeCQAAEAxa9YoVAAQTVqwAtOrtFgAgmLhcLs2ZM8fvk8AA2hdWrAAAABzCihUAAIBDKFYAAAAOoVgBAAA4hGIFAADgEIoVAACAQyhWAAAADqFYAQAAOIRiBQAA4BCKFQAAgEP+P+6qaCALvT63AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df['CTC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74820858-4f6f-4abf-bca9-a18b6d3eca3a",
   "metadata": {},
   "source": [
    "##### Note :- we see that outlier present in 'previous ctc' and 'ctc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24104063-1d22-4c6b-96db-16bbeaaf421d",
   "metadata": {},
   "source": [
    "##### <b> Outlier treatment in previous ctc column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "22089f59-f03e-46df-82f2-11d2ba571c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is upper limit 74495.5\n",
      "This is lower limit 36131.5\n"
     ]
    }
   ],
   "source": [
    "percent25 = df['Previous CTC'].quantile(0.25)  #getting 25 percentile value\n",
    "percent75 = df['Previous CTC'].quantile(0.75)  #getting 75 percentile value\n",
    "\n",
    "iqr = percent75-percent25    #calculation our 50% data range\n",
    "\n",
    "#setting upper and lower limit\n",
    "upper_limit = percent75 + 1.5*iqr\n",
    "lower_limit = percent25 - 1.5*iqr\n",
    "\n",
    "print(\"This is upper limit\", upper_limit)\n",
    "print(\"This is lower limit\", lower_limit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2c66fa1a-c727-4aeb-b1ae-a49efb7c76a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>College</th>\n",
       "      <th>City</th>\n",
       "      <th>Previous CTC</th>\n",
       "      <th>Previous job change</th>\n",
       "      <th>Graduation Marks</th>\n",
       "      <th>EXP (Month)</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Role_Manager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77911</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "      <td>87831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>75785</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>110338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76815</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>52</td>\n",
       "      <td>82684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>76070</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>18</td>\n",
       "      <td>58309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>77911</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "      <td>87831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      College  City  Previous CTC  Previous job change  Graduation Marks  \\\n",
       "116         1     1         77911                    1                50   \n",
       "860         3     1         75785                    4                63   \n",
       "1088        1     1         76815                    4                75   \n",
       "1317        3     0         76070                    2                54   \n",
       "1454        3     1         77911                    1                50   \n",
       "\n",
       "      EXP (Month)     CTC  Role_Manager  \n",
       "116            58   87831             0  \n",
       "860            37  110338             1  \n",
       "1088           52   82684             0  \n",
       "1317           18   58309             0  \n",
       "1454           58   87831             0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing outliers of previous ctc\n",
    "df[(df['Previous CTC'] < lower_limit) | (df['Previous CTC'] > upper_limit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3738d39b-c588-470b-b11a-9f998cd5e278",
   "metadata": {},
   "source": [
    "##### Note :- as we see outlier are not so large and may not effect the predictor so we can continue with these outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bad03b-9e08-46d5-b3bd-0c53b822f7c0",
   "metadata": {},
   "source": [
    "##### <B> Outlier treatment in CTC column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f42c7715-7b40-417c-bfda-e09362754f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is upper limit 101117.0\n",
      "This is lower limit 46373.0\n"
     ]
    }
   ],
   "source": [
    "percent25 = df['CTC'].quantile(0.25)  #getting 25 percentile value\n",
    "percent75 = df['CTC'].quantile(0.75)  #getting 75 percentile value\n",
    "\n",
    "iqr = percent75-percent25    #calculation our 50% data range\n",
    "\n",
    "#setting upper and lower limit\n",
    "upper_limit = percent75 + 1.5*iqr\n",
    "lower_limit = percent25 - 1.5*iqr\n",
    "\n",
    "print(\"This is upper limit\", upper_limit)\n",
    "print(\"This is lower limit\", lower_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ff5537d-a5f2-4161-afdb-35db839c170b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>College</th>\n",
       "      <th>City</th>\n",
       "      <th>Previous CTC</th>\n",
       "      <th>Previous job change</th>\n",
       "      <th>Graduation Marks</th>\n",
       "      <th>EXP (Month)</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Role_Manager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66487</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>27</td>\n",
       "      <td>103595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>65172</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>107138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>58529</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>102763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>60894</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>28</td>\n",
       "      <td>118651</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>57485</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>35</td>\n",
       "      <td>103774</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59099</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>63</td>\n",
       "      <td>103305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>55440</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>44</td>\n",
       "      <td>112826</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>58639</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>63</td>\n",
       "      <td>109108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>70258</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>115126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>53027</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>55</td>\n",
       "      <td>106846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      College  City  Previous CTC  Previous job change  Graduation Marks  \\\n",
       "14          1     0         66487                    1                50   \n",
       "29          2     0         65172                    1                44   \n",
       "30          3     0         58529                    1                65   \n",
       "34          3     0         60894                    4                80   \n",
       "38          2     0         57485                    1                77   \n",
       "...       ...   ...           ...                  ...               ...   \n",
       "1447        1     0         59099                    2                67   \n",
       "1461        3     0         55440                    4                72   \n",
       "1513        1     0         58639                    2                46   \n",
       "1523        2     1         70258                    4                38   \n",
       "1580        3     1         53027                    4                69   \n",
       "\n",
       "      EXP (Month)     CTC  Role_Manager  \n",
       "14             27  103595             1  \n",
       "29             31  107138             1  \n",
       "30             22  102763             1  \n",
       "34             28  118651             1  \n",
       "38             35  103774             1  \n",
       "...           ...     ...           ...  \n",
       "1447           63  103305             1  \n",
       "1461           44  112826             1  \n",
       "1513           63  109108             1  \n",
       "1523           36  115126             1  \n",
       "1580           55  106846             0  \n",
       "\n",
       "[94 rows x 8 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['CTC'] < lower_limit) | (df['CTC'] > upper_limit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae05cea-2a56-4d6a-8fb2-0643e29da486",
   "metadata": {},
   "source": [
    "##### Note :- here also we see that outlier are not very large they are nearby upper limit and lower limit so we are continuing with outlier as it will not affect our predictor that much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119e9406-8d80-442c-93bd-249c6cd24d56",
   "metadata": {},
   "source": [
    "#### <b> Feedback from pre processing </b>\n",
    "\n",
    "- We see outliers in CTC and Previous CTC\n",
    "- I think that the outlier are not large and they can't effect our predictor so that there is no need to remove the outlier\n",
    "- In correlation anlysis we dont see any correlation greater than 0.80 or less that -0.80 . so, not need to remove columns\n",
    "- We created dummy for role manager\n",
    "- We divided colleges in tier 1 ,2, 3 and cities in metro 0, 1\n",
    "- There is nothing to fill null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aec514-0b87-40c8-a2bf-2f2d198d26f0",
   "metadata": {},
   "source": [
    "### <b>  3. Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e915adb-f676-4150-8378-6ae690fccbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into dependent and Independent Variable\n",
    "\n",
    "X = df.loc[:, df.columns != 'CTC']\n",
    "y = df['CTC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3a677930-2788-4024-a717-5f1c88a1f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into train and test with test_size = 0.2(80% data into train and 20% to test)\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae1c87-4e5c-427b-82ee-932f1bc6bd22",
   "metadata": {},
   "source": [
    "##### checking our train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cc8fe42a-b2b9-444f-8276-2a18a48b5566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1271, 7)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4193327-5ff2-4e19-a19e-97e85d5e3bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 7)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "90cfe6ac-3a3d-40e7-b416-621c9f73a40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1137    54865\n",
       "371     76946\n",
       "354     67305\n",
       "711     73486\n",
       "173     66726\n",
       "Name: CTC, dtype: int32"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6afd241c-5831-40e0-854c-0e945bf92404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1079    74059\n",
       "405     84692\n",
       "1492    75028\n",
       "239     71001\n",
       "610     62426\n",
       "Name: CTC, dtype: int32"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a378261-080c-447a-9223-bb46c460c131",
   "metadata": {},
   "source": [
    "### <B> 4. Model Selection and Statistics for accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b019b9-51d5-406b-8c7f-70e5321e43e7",
   "metadata": {},
   "source": [
    "### Machine Learning models without Feature Scaling and test size 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8442c933-8d95-4762-9f42-a5e8eec690dd",
   "metadata": {},
   "source": [
    "#### <b> A) Linear regression ( Without scaling test size 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d0e1b7a9-a9e8-4a7e-94ee-73873f1c15e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5e30dea9-b592-4a59-afa9-f29f25947110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef: [5.17506078e+02 4.82819963e+02 4.22240508e-01 8.73566281e+00\n",
      " 1.94069240e+00 2.43719557e+02 1.86020613e+04]\n",
      "Intercept: 37159.126641370385\n",
      "\n",
      "\n",
      "r2_score: 0.5933515097281492\n",
      "MAE: 7191.243727675015\n",
      "MSE: 77362921.92796242\n"
     ]
    }
   ],
   "source": [
    "# Create a LinearRegression model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "linear_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "linear_reg_pred = linear_reg.predict(X_test)\n",
    "\n",
    "# Print the coefficients of the linear regression model\n",
    "print(\"Coef:\",linear_reg.coef_)\n",
    "\n",
    "# Print the intercept of the linear regression model\n",
    "print(\"Intercept:\",linear_reg.intercept_)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Calculate and print the R-squared (r2) score\n",
    "print(\"r2_score:\",r2_score(y_test, linear_reg_pred))\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE)\n",
    "print(\"MAE:\", mean_absolute_error(y_test, linear_reg_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE)\n",
    "print(\"MSE:\", mean_squared_error(y_test, linear_reg_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f101f5-ee5d-433b-b641-d4a0501f7753",
   "metadata": {},
   "source": [
    "#### <b> B) Ridge regression ( Without scaling test size 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "964ecd58-a05d-483c-ac19-288307a02754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef: [5.17161801e+02 4.79869763e+02 4.22275368e-01 8.24720190e+00\n",
      " 1.96363858e+00 2.43684648e+02 1.85564736e+04]\n",
      "Intercept: 37169.85723257522\n",
      "\n",
      "\n",
      "r2_score: 0.5930057182880146\n",
      "MAE: 7194.744364673603\n",
      "MSE: 77428707.08843015\n"
     ]
    }
   ],
   "source": [
    "# Import the Ridge regression model\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=0.5, solver='cholesky')\n",
    "\n",
    "# Fit the model to training data\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "ridge_predict = ridge.predict(X_test)\n",
    "\n",
    "\n",
    "# Print the coefficients of the linear regression model\n",
    "print(\"Coef:\",ridge.coef_)\n",
    "\n",
    "# Print the intercept of the linear regression model\n",
    "print(\"Intercept:\",ridge.intercept_)\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# Calculate and print the R-squared (r2) score\n",
    "print(\"r2_score:\",r2_score(y_test, ridge_predict))\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE)\n",
    "print(\"MAE:\", mean_absolute_error(y_test, ridge_predict))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE)\n",
    "print(\"MSE:\", mean_squared_error(y_test, ridge_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e522e031-6bac-43b2-ab7b-8346f2259108",
   "metadata": {},
   "source": [
    "#### <b> C) Lasso regression ( Without scaling test size 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "93b7b38b-497f-41ab-86d5-a980a759b02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef: [5.17102591e+02 4.81558426e+02 4.22240141e-01 8.53043708e+00\n",
      " 1.93918921e+00 2.43715112e+02 1.86000759e+04]\n",
      "Intercept: 37161.797438206406\n",
      "\n",
      "\n",
      "r2_score: 0.5933369144690608\n",
      "MAE: 7191.387233580885\n",
      "MSE: 77365698.60589531\n"
     ]
    }
   ],
   "source": [
    "# importing model \n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create Lasso regression with default parameters\n",
    "lasso = Lasso(alpha=0.3)\n",
    "\n",
    "# Fit model with train data\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "lasso_pred = lasso.predict(X_test)\n",
    "\n",
    "# Print the coefficients of the linear regression model\n",
    "print(\"Coef:\",lasso.coef_)\n",
    "\n",
    "# Print the intercept of the linear regression model\n",
    "print(\"Intercept:\",lasso.intercept_)\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, lasso_pred))\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) to measure prediction accuracy\n",
    "print(\"MAE:\", mean_absolute_error(y_test, lasso_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to assess prediction accuracy\n",
    "print(\"MSE:\", mean_squared_error(y_test, lasso_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abc1ad3-7b9d-4fa1-aef2-598e6fff6af5",
   "metadata": {},
   "source": [
    "#### <b> D) Decsion tree ( Without scaling test size 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2503a166-0f97-4b0e-95fd-1098f3d73d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.5974116918866258\n",
      "MAE: 6780.105736940578\n",
      "MSE: 76590491.77549943\n"
     ]
    }
   ],
   "source": [
    "# Import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Create a DecisionTreeRegressor model max depth =4\n",
    "dtr = DecisionTreeRegressor(max_depth=4)\n",
    "\n",
    "# Train the model using the training data\n",
    "dtr.fit(X_train, y_train)\n",
    "\n",
    "# Train the model using the training data\n",
    "dtr_pred = dtr.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, dtr_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, dtr_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, dtr_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "47e89061-00c6-43cc-8eb5-83401a3c0062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.5974116918866258\n",
      "MAE: 6780.105736940578\n",
      "MSE: 76590491.77549943\n"
     ]
    }
   ],
   "source": [
    "#importing gridsearchcv to get best parameter of decision tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameters\n",
    "params_grid = {\"max_depth\": [4,5,6,7,8,9,10]}\n",
    "\n",
    "# Find best parameter for model\n",
    "grid_search = GridSearchCV(dtr, params_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "#fiting model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "grid_search.best_params_\n",
    "\n",
    "# we fited the best model of dfr to cvdfr\n",
    "cvdfr = grid_search.best_estimator_\n",
    "\n",
    "# Train the model using the training data\n",
    "cvdtr_pred = dtr.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, cvdtr_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, cvdtr_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, cvdtr_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "70fcc735-f8e0-4c5b-808b-fd7f4b67882b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters\n",
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feae907-0ee3-4232-be2d-819d46bf9318",
   "metadata": {},
   "source": [
    "### <B> E) Random forest ( Without scaling test size 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6ecbcefe-2185-4243-91d6-49e7fbc74749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.6393807361034886\n",
      "MAE: 6336.2163562319065\n",
      "MSE: 68606082.71260142\n"
     ]
    }
   ],
   "source": [
    "# Import Random Forest from sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create Random forest regression\n",
    "rnd = RandomForestRegressor(n_jobs=-1, max_features=5, min_samples_split=3)\n",
    "\n",
    "# Fit model on train data\n",
    "rnd.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "rnd_pred = rnd.predict(X_test)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, rnd_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, rnd_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, rnd_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b724f773-092d-460a-b2aa-0477d4a30cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.5974116918866258\n",
      "MAE: 6780.105736940578\n",
      "MSE: 76590491.77549943\n"
     ]
    }
   ],
   "source": [
    "#importing gridsearchcv to get best parameter of random forest regressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#parameter\n",
    "params_grid = {\"max_features\": [4,5,6,7,8,9,10],\n",
    "              \"min_samples_split\": [2,3,10]}\n",
    "\n",
    "\n",
    "# Find best parameter for model\n",
    "grid_search = GridSearchCV(rnd, params_grid, n_jobs=-1, cv=5)\n",
    "\n",
    "#fiting model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "grid_search.best_params_\n",
    "\n",
    "# we fited the best model of dfr to cvdfr\n",
    "cvrf = grid_search.best_estimator_\n",
    "\n",
    "# Train the model using the training data\n",
    "cvrf_pred = dtr.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, cvrf_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, cvrf_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, cvrf_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d31b8ef4-23d4-4f68-9797-bd8ba471b1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 4, 'min_samples_split': 3}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters\n",
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56410162-5f2f-4d68-80b2-45636310f204",
   "metadata": {},
   "source": [
    "### <B> F) Bagging ( Without scaling test size 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "01ef2fc6-cd23-44e2-9224-adc37c8c528c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.6393807361034886\n",
      "MAE: 6336.216356231907\n",
      "MSE: 68606082.71260142\n"
     ]
    }
   ],
   "source": [
    "# Import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Create a DecisionTreeRegressor model max depth =4\n",
    "dtr = DecisionTreeRegressor(max_depth=4)\n",
    "\n",
    "\n",
    "# Import Bagging from sklearn\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# Create bagging regression\n",
    "bgg = BaggingRegressor(estimator= dtr,bootstrap= True , n_jobs=-1,random_state=42)\n",
    "\n",
    "# Fit model on train data\n",
    "bgg.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "bgg_pred = rnd.predict(X_test)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, bgg_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, bgg_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, bgg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf74528-f7a3-4cb7-a9bb-b664c33c0fe5",
   "metadata": {},
   "source": [
    "### <B> G) Gradient boost ( Without scaling test size 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "25b124f0-161e-4d30-9c4c-d5ac6c8185ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.6393807361034886\n",
      "MAE: 6336.216356231906\n",
      "MSE: 68606082.71260142\n"
     ]
    }
   ],
   "source": [
    "# Import gradient boost from sklearn\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create gradient boost regression\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.2,random_state=42)\n",
    "\n",
    "# Fit model on train data\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "gbr_pred = rnd.predict(X_test)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, gbr_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, gbr_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, gbr_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9290dc8-df27-4804-afea-8bcb108515e4",
   "metadata": {},
   "source": [
    "### <B> H) Adaboost ( Without scaling test size 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "542726e9-efd9-40d6-9b58-63abdf6df607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.6393807361034886\n",
      "MAE: 6336.2163562319065\n",
      "MSE: 68606082.71260142\n"
     ]
    }
   ],
   "source": [
    "# Import Ada boost from sklearn\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Create Ada boost regression\n",
    "abr = AdaBoostRegressor(learning_rate=0.2)\n",
    "\n",
    "# Fit model on train data\n",
    "abr.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "abr_pred = rnd.predict(X_test)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, abr_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, abr_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, abr_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c0f0a5-2b0a-4606-b04d-cce46bcdcaa8",
   "metadata": {},
   "source": [
    "### <B> I)  XG boost ( Without scaling test size 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fed9e9bc-0a9c-476f-b781-33f94d2a5380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.6393807361034884\n",
      "MAE: 6336.216356231906\n",
      "MSE: 68606082.71260144\n"
     ]
    }
   ],
   "source": [
    "# Import XG boost from sklearn\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create xg boost regression\n",
    "xgbr = xgb.XGBRegressor(learning_rate=0.3,max_depth=4)\n",
    "\n",
    "# Fit model on train data\n",
    "xgbr.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "xgbr_pred = rnd.predict(X_test)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, xgbr_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, xgbr_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, xgbr_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7be8377-030e-4b59-8d0b-aa3f457e973f",
   "metadata": {},
   "source": [
    "### Machine Learning models without Feature Scaling and test size 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d085cc3c-9c3f-472c-b031-7c3b36c592d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into train and test with test_size = 0.1(90% data into train and 10% to test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3586e282-15b6-4d0d-b95b-043fec9516f3",
   "metadata": {},
   "source": [
    "#### <b> A) Linear regression (without Scaling and Test size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "540cc43b-cd1c-4dac-b832-7e8243b4781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "54cb9acc-c619-4dca-9f35-d402ba5c1567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef: [4.42913287e+02 5.25781984e+02 4.08209815e-01 9.22824807e+01\n",
      " 2.31554348e+00 2.51618746e+02 1.89309661e+04]\n",
      "Intercept: 37413.163158355565\n",
      "\n",
      "\n",
      "r2_score: 0.6363230307340051\n",
      "MAE: 7264.585675989767\n",
      "MSE: 75992462.43827613\n"
     ]
    }
   ],
   "source": [
    "# Create a LinearRegression model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "linear_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "linear_reg_pred = linear_reg.predict(X_test)\n",
    "\n",
    "# Print the coefficients of the linear regression model\n",
    "print(\"Coef:\",linear_reg.coef_)\n",
    "\n",
    "# Print the intercept of the linear regression model\n",
    "print(\"Intercept:\",linear_reg.intercept_)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Calculate and print the R-squared (r2) score\n",
    "print(\"r2_score:\",r2_score(y_test, linear_reg_pred))\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE)\n",
    "print(\"MAE:\", mean_absolute_error(y_test, linear_reg_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE)\n",
    "print(\"MSE:\", mean_squared_error(y_test, linear_reg_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a081adc2-47ff-40af-aafc-c931318fca15",
   "metadata": {},
   "source": [
    "#### <b> B) Ridge regression (without Scaling and Test size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e177ee0c-2f04-43b0-8983-f9b4642a6e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef: [4.42890012e+02 5.23247292e+02 4.08231853e-01 9.20977545e+01\n",
      " 2.33314683e+00 2.51588124e+02 1.88897863e+04]\n",
      "Intercept: 37422.2327130619\n",
      "\n",
      "\n",
      "r2_score: 0.6359668884558288\n",
      "MAE: 7269.101530396075\n",
      "MSE: 76066880.48226614\n"
     ]
    }
   ],
   "source": [
    "# Import the Ridge regression model\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=0.5, solver='cholesky')\n",
    "\n",
    "# Fit the model to training data\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "ridge_predict = ridge.predict(X_test)\n",
    "\n",
    "\n",
    "# Print the coefficients of the linear regression model\n",
    "print(\"Coef:\",ridge.coef_)\n",
    "\n",
    "# Print the intercept of the linear regression model\n",
    "print(\"Intercept:\",ridge.intercept_)\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# Calculate and print the R-squared (r2) score\n",
    "print(\"r2_score:\",r2_score(y_test, ridge_predict))\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE)\n",
    "print(\"MAE:\", mean_absolute_error(y_test, ridge_predict))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE)\n",
    "print(\"MSE:\", mean_squared_error(y_test, ridge_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426c0b36-c6f1-4304-94c1-b3d3ea72e3b2",
   "metadata": {},
   "source": [
    "#### <b> C) Lasso regression (without Scaling and Test size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9d6e01dc-6001-4032-9aa5-bc26ee543e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef: [4.42514594e+02 5.24517798e+02 4.08208156e-01 9.20872339e+01\n",
      " 2.31393492e+00 2.51614466e+02 1.89290158e+04]\n",
      "Intercept: 37415.862644384775\n",
      "\n",
      "\n",
      "r2_score: 0.6363083020390154\n",
      "MAE: 7264.798325434058\n",
      "MSE: 75995540.08656114\n"
     ]
    }
   ],
   "source": [
    "# importing model \n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create Lasso regression with default parameters\n",
    "lasso = Lasso(alpha=0.3)\n",
    "\n",
    "# Fit model with train data\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "lasso_pred = lasso.predict(X_test)\n",
    "\n",
    "# Print the coefficients of the linear regression model\n",
    "print(\"Coef:\",lasso.coef_)\n",
    "\n",
    "# Print the intercept of the linear regression model\n",
    "print(\"Intercept:\",lasso.intercept_)\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, lasso_pred))\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) to measure prediction accuracy\n",
    "print(\"MAE:\", mean_absolute_error(y_test, lasso_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to assess prediction accuracy\n",
    "print(\"MSE:\", mean_squared_error(y_test, lasso_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae867c3-c8bf-42c3-b5a0-eddf574a3644",
   "metadata": {},
   "source": [
    "#### <b> D) Decsion tree (without Scaling and Test size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "878cb43b-cee8-4276-9842-60cb32c19b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.6302598008039058\n",
      "MAE: 7013.488193238541\n",
      "MSE: 77259410.33890247\n"
     ]
    }
   ],
   "source": [
    "# Import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Create a DecisionTreeRegressor model max depth =4\n",
    "dtr = DecisionTreeRegressor(max_depth=4)\n",
    "\n",
    "# Train the model using the training data\n",
    "dtr.fit(X_train, y_train)\n",
    "\n",
    "# Train the model using the training data\n",
    "dtr_pred = dtr.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, dtr_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, dtr_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, dtr_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e8e8c3-bda2-43fe-863a-40afd4bf0ece",
   "metadata": {},
   "source": [
    "### <B> E) Random forest (without Scaling and Test size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8bbf46cf-f6fe-47a6-a08a-668f71828af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.6926755481204343\n",
      "MAE: 6333.212153538984\n",
      "MSE: 64217269.27871594\n"
     ]
    }
   ],
   "source": [
    "# Import Random Forest from sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create Random forest regression\n",
    "rnd = RandomForestRegressor(n_jobs=-1, max_features=5, min_samples_split=3,random_state=34)\n",
    "\n",
    "# Fit model on train data\n",
    "rnd.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "rnd_pred = rnd.predict(X_test)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, rnd_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, rnd_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, rnd_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75287f76-cda3-4370-85ee-2f5ec7d96afd",
   "metadata": {},
   "source": [
    "### <B> F) Bagging ( Without scaling test size 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ba49efff-b33d-406c-8f2b-3a3c6b3a3122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.6926755481204343\n",
      "MAE: 6333.212153538984\n",
      "MSE: 64217269.27871594\n"
     ]
    }
   ],
   "source": [
    "# Import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Create a DecisionTreeRegressor model max depth =4\n",
    "dtr = DecisionTreeRegressor(max_depth=4)\n",
    "\n",
    "\n",
    "# Import Bagging from sklearn\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# Create bagging regression\n",
    "bgg = BaggingRegressor(estimator= dtr,bootstrap= True , n_jobs=-1,random_state=42)\n",
    "\n",
    "# Fit model on train data\n",
    "bgg.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "bgg_pred = rnd.predict(X_test)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, bgg_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, bgg_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, bgg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c801c611-d417-4f64-8878-614770d27348",
   "metadata": {},
   "source": [
    "### <B> G) Gradient boost ( Without scaling test size 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "745fb8da-4cb8-482c-b5e3-41d825855ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.6926755481204343\n",
      "MAE: 6333.212153538984\n",
      "MSE: 64217269.27871594\n"
     ]
    }
   ],
   "source": [
    "# Import gradient boost from sklearn\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create gradient boost regression\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.2,random_state=42)\n",
    "\n",
    "# Fit model on train data\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "gbr_pred = rnd.predict(X_test)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, gbr_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, gbr_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, gbr_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a046f4d-fec3-4730-9b8a-d21c9640cdbe",
   "metadata": {},
   "source": [
    "### <B> H) Adaboost ( Without scaling test size 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d41d9cb6-356e-4de6-9ce8-3ade3a6939f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.6926755481204343\n",
      "MAE: 6333.212153538984\n",
      "MSE: 64217269.27871592\n"
     ]
    }
   ],
   "source": [
    "# Import Ada boost from sklearn\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Create Ada boost regression\n",
    "abr = AdaBoostRegressor(learning_rate=0.2)\n",
    "\n",
    "# Fit model on train data\n",
    "abr.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "abr_pred = rnd.predict(X_test)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, abr_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, abr_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, abr_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d5b642-dd81-41dd-8c2c-cda1933d3b63",
   "metadata": {},
   "source": [
    "### <B> I)  XG boost ( Without scaling test size 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "50e724e4-729c-425c-973e-4b6295dc5244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.6926755481204343\n",
      "MAE: 6333.212153538984\n",
      "MSE: 64217269.27871594\n"
     ]
    }
   ],
   "source": [
    "# Import XG boost from sklearn\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create xg boost regression\n",
    "xgbr = xgb.XGBRegressor(learning_rate=0.3,max_depth=4)\n",
    "\n",
    "# Fit model on train data\n",
    "xgbr.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "xgbr_pred = rnd.predict(X_test)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, xgbr_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, xgbr_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, xgbr_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea35d3f-65d2-41b7-a5ee-d1b3020427c8",
   "metadata": {},
   "source": [
    "### scaling the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "82460484-3900-4b71-9b29-3de793cbcf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into independent and target variable\n",
    "X = df.loc[:, df.columns != 'CTC']\n",
    "y = df['CTC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d6b47cf2-76c1-410b-8079-66fc42d2f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into train and test with test_size = 0.1(90% data into train and 10% to test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "947b2989-30c0-4b88-b185-6f424f14d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard scaler from sklearn for feature scaling(mean=0, std dev=1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create standard scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the features in the training data using a previously fitted scaler\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Scale the features in the test data using the same scaler to ensure consistency\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5421d04d-80cc-46ba-8f78-1fe38e79a1ef",
   "metadata": {},
   "source": [
    "### Machine Learning models without Feature Scaling and test size 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b702e8ae-76d9-44c4-8408-326c66ed4d7f",
   "metadata": {},
   "source": [
    "#### <b> A) Linear regression (with Scaling and Test size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "27ce345c-4455-4a54-a773-843b7b5fc8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef: [ 370.67836782  262.77757829 2712.43254456  103.76361161   34.54979686\n",
      " 3569.08782057 7602.01084896]\n",
      "Intercept: 75275.75664335664\n",
      "\n",
      "\n",
      "r2_score: 0.6363230307340061\n",
      "MAE: 7264.585675989758\n",
      "MSE: 75992462.43827592\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a LinearRegression model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "linear_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "linear_reg_pred = linear_reg.predict(X_test_scaled)\n",
    "\n",
    "# Print the coefficients of the linear regression model\n",
    "print(\"Coef:\",linear_reg.coef_)\n",
    "\n",
    "# Print the intercept of the linear regression model\n",
    "print(\"Intercept:\",linear_reg.intercept_)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Calculate and print the R-squared (r2) score\n",
    "print(\"r2_score:\",r2_score(y_test, linear_reg_pred))\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE)\n",
    "print(\"MAE:\", mean_absolute_error(y_test, linear_reg_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE)\n",
    "print(\"MSE:\", mean_squared_error(y_test, linear_reg_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2dfede-f7cc-4a8f-afe6-07d163f29add",
   "metadata": {},
   "source": [
    "#### <b> B) Ridge regression (with Scaling and Test size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "012bc032-f510-4cd7-a2a8-efd82e6ed2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef: [ 370.50683175  262.49479816 2711.64126055  103.74538206   34.48850335\n",
      " 3567.85971617 7599.31614652]\n",
      "Intercept: 75275.75664335664\n",
      "\n",
      "\n",
      "r2_score: 0.6362480719447947\n",
      "MAE: 7265.500068274926\n",
      "MSE: 76008125.5224274\n"
     ]
    }
   ],
   "source": [
    "# Import the Ridge regression model\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=0.5, solver='cholesky')\n",
    "\n",
    "# Fit the model to training data\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "ridge_predict = ridge.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Print the coefficients of the linear regression model\n",
    "print(\"Coef:\",ridge.coef_)\n",
    "\n",
    "# Print the intercept of the linear regression model\n",
    "print(\"Intercept:\",ridge.intercept_)\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# Calculate and print the R-squared (r2) score\n",
    "print(\"r2_score:\",r2_score(y_test, ridge_predict))\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE)\n",
    "print(\"MAE:\", mean_absolute_error(y_test, ridge_predict))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE)\n",
    "print(\"MSE:\", mean_squared_error(y_test, ridge_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce09597-b1df-4c86-9607-0395c14ea4c1",
   "metadata": {},
   "source": [
    "#### <b> C) Lasso regression (with Scaling and Test size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3fa2028c-8b9c-4a13-83db-521476d1a4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef: [ 370.37771845  262.45627658 2712.14530327  103.50874793   34.2235039\n",
      " 3568.78730724 7601.69257588]\n",
      "Intercept: 75275.75664335664\n",
      "\n",
      "\n",
      "r2_score: 0.6363105168145384\n",
      "MAE: 7264.762446482099\n",
      "MSE: 75995077.2960631\n"
     ]
    }
   ],
   "source": [
    "# importing model \n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create Lasso regression with default parameters\n",
    "lasso = Lasso(alpha=0.3)\n",
    "\n",
    "# Fit model with train data\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "lasso_pred = lasso.predict(X_test_scaled)\n",
    "\n",
    "# Print the coefficients of the linear regression model\n",
    "print(\"Coef:\",lasso.coef_)\n",
    "\n",
    "# Print the intercept of the linear regression model\n",
    "print(\"Intercept:\",lasso.intercept_)\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, lasso_pred))\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE) to measure prediction accuracy\n",
    "print(\"MAE:\", mean_absolute_error(y_test, lasso_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to assess prediction accuracy\n",
    "print(\"MSE:\", mean_squared_error(y_test, lasso_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9141ba-7abf-4073-964f-3de9be9f7d31",
   "metadata": {},
   "source": [
    "#### <b> D) Decsion tree (with Scaling and Test size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d682449b-962e-43e7-82db-d62b63bd4aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.6302598008039058\n",
      "MAE: 7013.488193238541\n",
      "MSE: 77259410.33890247\n"
     ]
    }
   ],
   "source": [
    "# Import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Create a DecisionTreeRegressor model max depth =4\n",
    "dtr = DecisionTreeRegressor(max_depth=4)\n",
    "\n",
    "# Train the model using the training data\n",
    "dtr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Train the model using the training data\n",
    "dtr_pred = dtr.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, dtr_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, dtr_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, dtr_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2e2ead-eeff-4ad8-94ce-5b1a23a5bf8d",
   "metadata": {},
   "source": [
    "### <B> E) Random forest (without Scaling and Test size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "003ac422-5897-4b5d-ae9d-96ab6f8d4a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.6926755481204343\n",
      "MAE: 6333.212153538984\n",
      "MSE: 64217269.27871594\n"
     ]
    }
   ],
   "source": [
    "# Import Random Forest from sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create Random forest regression\n",
    "rnd = RandomForestRegressor(n_jobs=-1, max_features=5, min_samples_split=3,random_state=34)\n",
    "\n",
    "# Fit model on train data\n",
    "rnd.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "rnd_pred = rnd.predict(X_test)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, rnd_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, rnd_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, rnd_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b338bce7-6ee0-4c04-949a-3a616f081be6",
   "metadata": {},
   "source": [
    "### <B> F) Bagging ( Without scaling test size 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a8ffe431-5fb5-4a0b-8ece-375087fdfbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.07633382384535359\n",
      "MAE: 10251.814823300387\n",
      "MSE: 193005532.7358374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Create a DecisionTreeRegressor model max depth =4\n",
    "dtr = DecisionTreeRegressor(max_depth=4)\n",
    "\n",
    "\n",
    "# Import Bagging from sklearn\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# Create bagging regression\n",
    "bgg = BaggingRegressor(estimator= dtr,bootstrap= True , n_jobs=-1,random_state=42)\n",
    "\n",
    "# Fit model on train data\n",
    "bgg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "bgg_pred = rnd.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, bgg_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, bgg_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, bgg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6419ee-0a2f-4f21-a54d-86735f5590cf",
   "metadata": {},
   "source": [
    "### <B> G) Gradient boost ( With scaling test size 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "49919d8a-e699-425e-9729-ac4baac8a762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.07633382384535392\n",
      "MAE: 10251.814823300387\n",
      "MSE: 193005532.7358373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import gradient boost from sklearn\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create gradient boost regression\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.2,random_state=42)\n",
    "\n",
    "# Fit model on train data\n",
    "gbr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "gbr_pred = rnd.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, gbr_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, gbr_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, gbr_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822b44bc-afcb-4848-9f38-3c75eb2699f1",
   "metadata": {},
   "source": [
    "### <B> H) Adaboost ( With scaling test size 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "cf5fd004-9f90-4e9e-b04b-360e64f02f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.07633382384535359\n",
      "MAE: 10251.814823300387\n",
      "MSE: 193005532.7358374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import Ada boost from sklearn\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Create Ada boost regression\n",
    "abr = AdaBoostRegressor(learning_rate=0.2)\n",
    "\n",
    "# Fit model on train data\n",
    "abr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "abr_pred = rnd.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, abr_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, abr_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, abr_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a87454e-b6d2-4396-b1fd-fa25752fc2fe",
   "metadata": {},
   "source": [
    "### <B> I)  XG boost ( With scaling test size 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "52be8c95-318f-4319-a2cd-353da7b94787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.07633382384535392\n",
      "MAE: 10251.814823300387\n",
      "MSE: 193005532.7358373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import XG boost from sklearn\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create xg boost regression\n",
    "xgbr = xgb.XGBRegressor(learning_rate=0.3,max_depth=4)\n",
    "\n",
    "# Fit model on train data\n",
    "xgbr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make prediction on test data\n",
    "xgbr_pred = rnd.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print the R-squared (r2) score to evaluate model performance\n",
    "print(\"r2_score:\",r2_score(y_test, xgbr_pred))\n",
    "\n",
    "# Calculate and print the mean absolute error(MSE) score to evaluate model performance\n",
    "print(\"MAE:\", mean_absolute_error(y_test, xgbr_pred))\n",
    "\n",
    "# Calculate and print the Mean Squared Error (MSE) to evaluate prediction errors\n",
    "print(\"MSE:\", mean_squared_error(y_test, xgbr_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e0790e-ff8e-4f83-b0b7-b135fe164137",
   "metadata": {},
   "source": [
    "### <B> 4. Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6564dc-d333-4906-b115-3ed27d321f70",
   "metadata": {},
   "source": [
    "To compare the performance of different machine learning models, we will focus on the R-squared (r2_score) metric, which measures the goodness of fit of the models. A higher R-squared indicates a better fit to the data. \n",
    "\n",
    "<B> Summary in three cases </B>\n",
    "\n",
    "**Case 1 (Test size = 0.2):**\n",
    "- Linear Regression: r2_score = 0.5933515097281492\n",
    "- Ridge: r2_score = 0.5930057182880146\n",
    "- Lasso: r2_score = 0.5933369144690608\n",
    "- Decision Tree: r2_score = 0.5974116918866258\n",
    "- Random Forest: r2_score = 0.6321811755180589\n",
    "- Bagging : r2_score = 0.6321811755180589\n",
    "- Gradient boost : r2_score = 0.6321811755180589\n",
    "- Adaboost : r2_score = 0.6321811755180587\n",
    "- XG Boost : r2_score = 0.6321811755180589\n",
    "\n",
    "**Case 2 (Test size = 0.1):**\n",
    "- Linear Regression: r2_score = 0.6363230307340051\n",
    "- Ridge: r2_score = 0.6359668884558288\n",
    "- Lasso: r2_score = 0.6363083020390154\n",
    "- Decision Tree: r2_score = 0.6302598008039058\n",
    "- Random Forest: r2_score = 0.6926755481204343\n",
    "- Bagging : r2_score = 0.6926755481204343\n",
    "- Gradient boost : r2_score = 0.6926755481204343\n",
    "- Adaboost : r2_score = 0.6926755481204343\n",
    "- XG Boost : r2_score = 0.6926755481204343\n",
    "\n",
    "**Case 3 (Test size = 0.1 with feature scaling):**\n",
    "- Linear Regression: r2_score = 0.6363230307340061\n",
    "- Ridge: r2_score = 0.6362480719447947\n",
    "- Lasso: r2_score = 0.6363105168145384\n",
    "- Decision Tree: r2_score = 0.6302598008039058\n",
    "- Random Forest: r2_score = 0.6926755481204343\n",
    "- Bagging : r2_score = 0.07633382384535392\n",
    "- Gradient boost : r2_score = 0.07633382384535425\n",
    "- Adaboost : r2_score = 0.07633382384535359\n",
    "- XG Boost : r2_score = 0.07633382384535359\n",
    "\n",
    "  \n",
    "**Summary:**\n",
    "- Among the different models, Random Forest consistently performs well in all Cases with or without feature scaling, and with varying test sizes. It achieves the highest R-squared scores, indicating a good fit to the data.\n",
    "- Decision Tree gives lowest R-square scores in without scaling and test sizes 0.1 and 0.2.\n",
    "- Feature scaling increase the R-square scores of many models , but in case of bagging and boosting models scaling does not work properly they achive the lowest accuracy in featre scaling.\n",
    "\n",
    "Overall, if we consider R-squared as the primary metric for model performance, Random Forest is the top performer, followed by Linear Regression and Lasso. It's essential to consider other factors like computational efficiency, model interpretability, and the specific goals of your application when choosing the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfa1a64-b9cb-40c4-8766-2160fa687fe9",
   "metadata": {},
   "source": [
    "### <B> 5. Future improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7734d9-56e3-48a4-a032-21b28ac6044c",
   "metadata": {},
   "source": [
    "#### Steps to increase model performance\n",
    "- **Increase the Number of Trees (Estimators):**\n",
    "    Random Forest's performance often benefits from increasing the number of decision trees (estimators) in the ensemble.\n",
    "- **Tune Hyperparameters:** Perform a more thorough hyperparameter tuning by experimenting with different values for parameters like max_depth, min_samples_split, min_samples_leaf, and max_features. Grid Search or Randomized Search can help find the optimal combination of hyperparameters.\n",
    "- **Feature Selection:** Consider removing or reducing the importance of less informative features to improve the model's efficiency and potentially its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d88c2-9a82-439b-a2e7-638e586838e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846fe41e-7c67-4b28-bc91-993e907eebd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
